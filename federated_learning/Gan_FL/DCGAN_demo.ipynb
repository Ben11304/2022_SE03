{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_TwwmUULgT6"
      },
      "source": [
        "#Data to fix model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "wCmOJiuDqKJB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def get_sublabel(df, label_name: str):\n",
        "    unique_labels = df[label_name].unique()\n",
        "    small_dataframes = {}\n",
        "    for label in unique_labels:\n",
        "        small_dataframes[label] = df[df[label_name] == label]\n",
        "    return small_dataframes\n",
        "\n",
        "\n",
        "def data_split(data,label_name: str, num_partitions: int, val_ratio: float = 0.1, IID: bool=True , clusted_in_subdata: int=1):\n",
        "    '''\n",
        "    data: input data\n",
        "    label_name: name of target label in data\n",
        "    num_partitions: number of Subdataset\n",
        "    IID: (False for non iid data split)\n",
        "    val_ratio: rate of validation data\n",
        "    test_ratio: rate of test data\n",
        "    '''\n",
        "    if not IID :\n",
        "        print(\"prepairing non IID dataset\")\n",
        "        length=len(data)\n",
        "        partition_size=int(length/num_partitions)\n",
        "        partition_len_list = [partition_size] * num_partitions\n",
        "        print(f\"len of client data :{partition_size * num_partitions}, len of each subdata : {partition_size}\")\n",
        "        data = data[:int(partition_size * num_partitions)]\n",
        "        df_sorted = data.sort_values(by=label_name)\n",
        "        df=df_sorted.reset_index(drop=True)\n",
        "\n",
        "        partitions=[]\n",
        "        start=0\n",
        "        for num in partition_len_list:\n",
        "            partitions.append(df[start:start+num])\n",
        "            start=start+num\n",
        "        num=1\n",
        "        trainloaders = []\n",
        "        valloaders = []\n",
        "        for client in partitions:\n",
        "            len_val = int(val_ratio * len(client))\n",
        "            len_train = len(client) - len_val\n",
        "            print(f\"client number {num} : train({len_train}), val({len_val})\")\n",
        "            num=num+1\n",
        "            client = client.sample(frac=1).reset_index(drop=True)\n",
        "            val_data=client[0:len_val]\n",
        "            train_data=client[len_val:]\n",
        "            train_data = train_data.reset_index(drop=True)\n",
        "            val_data=val_data.reset_index(drop=True)\n",
        "            trainloaders.append(train_data)\n",
        "            valloaders.append(val_data)\n",
        "\n",
        "    if IID:\n",
        "        print(\"prepairing IID dataset\")\n",
        "        partition_size = int(len(data) // num_partitions)\n",
        "        partition_len_list = [partition_size] * num_partitions\n",
        "        print(f\"len of client data :{len(data)}, len of each subdata : {partition_size}\")\n",
        "        df = data[:int(partition_size * num_partitions)]\n",
        "        partitions=[]\n",
        "        start=0\n",
        "        for num in partition_len_list:\n",
        "            partitions.append(df[start:start+num])\n",
        "            start=start+num\n",
        "\n",
        "        trainloaders = []\n",
        "        valloaders = []\n",
        "        num=1\n",
        "        for client in partitions:\n",
        "            len_val = int(val_ratio * len(client))\n",
        "            len_train = len(client) - len_val\n",
        "            print(f\"client number {num} : train({len_train}), val({len_val})\")\n",
        "            num=num+1\n",
        "            val_data = client[0:len_val]\n",
        "            train_data=client[len_val:]\n",
        "            train_data = train_data.reset_index(drop=True)\n",
        "            val_data=val_data.reset_index(drop=True)\n",
        "            trainloaders.append(train_data)\n",
        "            valloaders.append(val_data)\n",
        "    return trainloaders, valloaders\n",
        "\n",
        "def identify_correlated(df, threshold):\n",
        "    \"\"\"\n",
        "    A function to identify highly correlated features.\n",
        "    \"\"\"\n",
        "    # Compute correlation matrix with absolute values\n",
        "    #df=df.drop(\"category\",axis=1)\n",
        "    matrix = df.corr().abs()\n",
        "\n",
        "    # Create a boolean mask\n",
        "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
        "\n",
        "    # Subset the matrix\n",
        "    reduced_matrix = matrix.mask(mask)\n",
        "\n",
        "    # Find cols that meet the threshold\n",
        "    to_drop = [c for c in reduced_matrix.columns if any(reduced_matrix[c] > threshold)]\n",
        "\n",
        "    return to_drop\n",
        "\n",
        "def processed(data,label_name: str,threshold: int=0.01, corr_threshold=1):\n",
        "    label=data[label_name]\n",
        "    data=data.drop(label_name,axis=1)\n",
        "    data=pd.concat([label,data],axis=1)\n",
        "    data.astype(str)\n",
        "    df=data.dropna()\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_df = df.apply(label_encoder.fit_transform)\n",
        "    #feature selection\n",
        "    selector = VarianceThreshold(threshold=threshold)\n",
        "    filtered_df = selector.fit_transform(encoded_df)\n",
        "    filtered_df = pd.DataFrame(filtered_df, columns=df.columns[selector.get_support()])\n",
        "    #normalized\n",
        "    normalized_df=filtered_df.mean()\n",
        "    normalized_df=filtered_df.drop(identify_correlated(pd.DataFrame(normalized_df),corr_threshold),axis=1)\n",
        "    processed_data=normalized_df\n",
        "    processed_data=processed_data.sample(frac=1).reset_index(drop=True)\n",
        "    return processed_data\n",
        "\n",
        "def count_label_data(labels):\n",
        "    '''\n",
        "    this step use for analyse label\n",
        "    '''\n",
        "    label_counts = Counter(labels)\n",
        "    return label_counts\n",
        "\n",
        "def analyse_dataset(data,names):\n",
        "    list=[]\n",
        "    for name in names:\n",
        "        label_data_count = count_label_data(data[name])\n",
        "        print(f\"thống kê nhãn {name}:\")\n",
        "        for label, count in label_data_count.items():\n",
        "            list.append(label)\n",
        "            print(label, count)\n",
        "    return list\n",
        "\n",
        "\n",
        "def group_labels(label_counts, n):\n",
        "    grouped_labels = {}\n",
        "    labels = list(label_counts.keys())\n",
        "    # Duyệt qua từng cặp nhãn\n",
        "    for i in range(0, len(labels), n):\n",
        "        group =labels[i:i + n]\n",
        "        group_key = tuple(group)\n",
        "        group_count = sum(label_counts[label] for label in group)\n",
        "        grouped_labels[group_key] = group_count\n",
        "\n",
        "    return grouped_labels\n",
        "\n",
        "def set_data(loaders):\n",
        "    list=[]\n",
        "    for loader in loaders:\n",
        "        y=loader[\"subcategory \"]\n",
        "        X=loader.drop(\"subcategory \",axis=1)\n",
        "        print(f\"len X {len(X)}, len y {len(y)}\")\n",
        "        list.append((X,y))\n",
        "    return list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "VbUMd5etjJDQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df=pd.read_csv(\"2022_SE03\\federated_learning\\Data\\new2test.csv\")\n",
        "#delete all null columns\n",
        "id=[16,17,21,22,23,24]\n",
        "col=df.columns\n",
        "for idx in id:\n",
        "    df=df.drop(col[idx],axis=1)\n",
        "data=processed(df,\"subcategory \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80GHH-v1jJDd",
        "outputId": "b97da00a-d010-403a-f1a2-2e0f7968b3b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['subcategory ', 'pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport',\n",
              "       'daddr', 'dport', 'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur',\n",
              "       'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes',\n",
              "       'dbytes', 'rate', 'srate', 'drate', 'attack', 'category'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "TcSXJXXq4pSP"
      },
      "outputs": [],
      "source": [
        "X = data.drop(\"subcategory \",axis=1)\n",
        "y =data[\"subcategory \"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByvXysLD7kyA",
        "outputId": "c3cdca68-d042-4ee3-9451-d7770242518d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnOwD6jjgOLB"
      },
      "source": [
        "#Build MLP classifier model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tBJYJAiEYqfH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_size = 28\n",
        "        self.output_size = 8\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.lr = 0.003\n",
        "\n",
        "        self.l1 = nn.Linear(self.input_size, 256)\n",
        "        self.l2 = nn.Linear(256, 128)\n",
        "        self.l3 = nn.Linear(128, self.output_size)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.l1(inp))\n",
        "        out = F.relu(self.l2(out))\n",
        "        out = self.l3(out)\n",
        "        return out\n",
        "\n",
        "    def convert(self, X, y):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X.values, dtype=torch.float32)\n",
        "\n",
        "        if not isinstance(y, torch.Tensor):\n",
        "            y = torch.tensor(y.values)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
        "        for idx in range(X.shape[0]):\n",
        "\n",
        "            #Get data\n",
        "            features = torch.tensor([X.iloc[idx].values], dtype=torch.float, requires_grad = True)\n",
        "            target = torch.tensor([y.iloc[idx]])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self(features)\n",
        "            loss = self.criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if idx % 10 == 0:\n",
        "                print(f'Index {idx} - Loss: ', loss.item())\n",
        "\n",
        "    # def fit(self, X, y, num_epochs = 100):\n",
        "    #     X, y = self.convert(X, y)\n",
        "    #     for epoch in range(num_epochs):\n",
        "    #         optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
        "    #         # for idx in range(X.shape[0]):\n",
        "    #         #     data = torch.tensor([X.iloc[idx].values], dtype=torch.float, requires_grad = True)\n",
        "    #         #     target = torch.tensor([y.iloc[idx]])\n",
        "\n",
        "    #         optimizer.zero_grad()\n",
        "    #         output = self(X)\n",
        "    #         loss = self.criterion(output, y)\n",
        "    #         loss.backward()\n",
        "    #         optimizer.step()\n",
        "\n",
        "    #         print(f'Epoch {epoch} - Loss: ', loss.item())\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
        "        for idx in range(X.shape[0]):\n",
        "            features = torch.tensor([X.iloc[idx].values], dtype=torch.float, requires_grad = True)\n",
        "            target = torch.tensor([y.iloc[idx]])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self(features)\n",
        "            loss = self.criterion(output, target)\n",
        "\n",
        "            if idx % 100 == 0:\n",
        "                print(f'Index {idx} - Loss: ', loss.item())\n",
        "\n",
        "    def get_parameters(self):\n",
        "\n",
        "        params=self.state_dict()\n",
        "        parameters=[]\n",
        "        keys=[]\n",
        "        for key,tensor in params.items():\n",
        "            parameters.append(tensor)\n",
        "            keys.append(key)\n",
        "        self.params_key=keys\n",
        "        return parameters\n",
        "\n",
        "    def load_parameters(self, parameters_tensor):\n",
        "        # Đảm bảo số lượng tham số trùng khớp\n",
        "        assert len(self.params_key) == len(parameters_tensor), \"Số lượng tham số không khớp\"\n",
        "\n",
        "        # Cập nhật giá trị của các tham số\n",
        "        for key, tensor in zip(self.params_key, parameters_tensor):\n",
        "            self.state_dict()[key].copy_(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4z6N-h_5chL"
      },
      "source": [
        "##Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzCXXaLM2TLo",
        "outputId": "608f55ff-b3df-4b18-9bad-2090df309541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index 0 - Loss:  78.18795776367188\n",
            "Index 10 - Loss:  0.0\n",
            "Index 20 - Loss:  473.9438171386719\n",
            "Index 30 - Loss:  150.38128662109375\n",
            "Index 40 - Loss:  0.0\n",
            "Index 50 - Loss:  0.0\n",
            "Index 60 - Loss:  0.0\n",
            "Index 70 - Loss:  0.0\n",
            "Index 80 - Loss:  0.0\n",
            "Index 90 - Loss:  0.0\n",
            "Index 100 - Loss:  0.0\n",
            "Index 110 - Loss:  23.135604858398438\n",
            "Index 120 - Loss:  18.41197967529297\n",
            "Index 130 - Loss:  0.0\n",
            "Index 140 - Loss:  0.0\n",
            "Index 150 - Loss:  0.0\n",
            "Index 160 - Loss:  48.48945617675781\n",
            "Index 170 - Loss:  0.0\n",
            "Index 180 - Loss:  0.0\n",
            "Index 190 - Loss:  0.0\n",
            "Index 200 - Loss:  0.0\n",
            "Index 210 - Loss:  0.0\n",
            "Index 220 - Loss:  53.285736083984375\n",
            "Index 230 - Loss:  0.0\n",
            "Index 240 - Loss:  0.0\n",
            "Index 250 - Loss:  0.012643182650208473\n",
            "Index 260 - Loss:  0.0\n",
            "Index 270 - Loss:  0.4153975546360016\n",
            "Index 280 - Loss:  0.0\n",
            "Index 290 - Loss:  0.0\n",
            "Index 300 - Loss:  0.0\n",
            "Index 310 - Loss:  0.0\n",
            "Index 320 - Loss:  0.0\n",
            "Index 330 - Loss:  0.0\n",
            "Index 340 - Loss:  1.288478136062622\n",
            "Index 350 - Loss:  0.056239113211631775\n",
            "Index 360 - Loss:  0.0\n",
            "Index 370 - Loss:  0.0\n",
            "Index 380 - Loss:  0.2748340368270874\n",
            "Index 390 - Loss:  0.0\n",
            "Index 400 - Loss:  0.0\n",
            "Index 410 - Loss:  0.0\n",
            "Index 420 - Loss:  0.0\n",
            "Index 430 - Loss:  2.093539237976074\n",
            "Index 440 - Loss:  0.0\n",
            "Index 450 - Loss:  90.32017517089844\n",
            "Index 460 - Loss:  23.137462615966797\n",
            "Index 470 - Loss:  3.3062403202056885\n",
            "Index 480 - Loss:  0.0\n",
            "Index 490 - Loss:  0.0\n",
            "Index 500 - Loss:  0.019080430269241333\n",
            "Index 510 - Loss:  0.0\n",
            "Index 520 - Loss:  0.0\n",
            "Index 530 - Loss:  0.0007674132939428091\n",
            "Index 540 - Loss:  0.0\n",
            "Index 550 - Loss:  0.0\n",
            "Index 560 - Loss:  0.0\n",
            "Index 570 - Loss:  0.0\n",
            "Index 580 - Loss:  0.0\n",
            "Index 590 - Loss:  0.0\n",
            "Index 600 - Loss:  0.0\n",
            "Index 610 - Loss:  0.0\n",
            "Index 620 - Loss:  0.0\n",
            "Index 630 - Loss:  0.0\n",
            "Index 640 - Loss:  0.0\n",
            "Index 650 - Loss:  0.0\n",
            "Index 660 - Loss:  0.0\n",
            "Index 670 - Loss:  0.0\n",
            "Index 680 - Loss:  0.0\n",
            "Index 690 - Loss:  0.0\n",
            "Index 700 - Loss:  0.0\n",
            "Index 710 - Loss:  0.0\n",
            "Index 720 - Loss:  0.0\n",
            "Index 730 - Loss:  0.0\n",
            "Index 740 - Loss:  0.0\n",
            "Index 750 - Loss:  0.0\n",
            "Index 760 - Loss:  0.0\n",
            "Index 770 - Loss:  0.0\n",
            "Index 780 - Loss:  0.0\n",
            "Index 790 - Loss:  0.0\n",
            "Index 800 - Loss:  12.023303985595703\n",
            "Index 810 - Loss:  49.69312286376953\n",
            "Index 820 - Loss:  0.0\n",
            "Index 830 - Loss:  0.0\n",
            "Index 840 - Loss:  0.0\n",
            "Index 850 - Loss:  0.0\n",
            "Index 860 - Loss:  0.0\n",
            "Index 870 - Loss:  26.02768325805664\n",
            "Index 880 - Loss:  0.0\n",
            "Index 890 - Loss:  0.0\n",
            "Index 900 - Loss:  0.0\n",
            "Index 910 - Loss:  1.7404405298293568e-05\n",
            "Index 920 - Loss:  0.0\n",
            "Index 930 - Loss:  0.0\n",
            "Index 940 - Loss:  0.0\n",
            "Index 950 - Loss:  0.0\n",
            "Index 960 - Loss:  0.0\n",
            "Index 970 - Loss:  0.0\n",
            "Index 980 - Loss:  0.0\n",
            "Index 990 - Loss:  0.0\n",
            "Index 1000 - Loss:  0.0\n",
            "Index 1010 - Loss:  0.0\n",
            "Index 1020 - Loss:  0.0\n",
            "Index 1030 - Loss:  0.0006834316882304847\n",
            "Index 1040 - Loss:  0.0\n",
            "Index 1050 - Loss:  0.0\n",
            "Index 1060 - Loss:  0.0\n",
            "Index 1070 - Loss:  0.0\n",
            "Index 1080 - Loss:  0.0\n",
            "Index 1090 - Loss:  0.004115208517760038\n",
            "Index 1100 - Loss:  0.0\n",
            "Index 1110 - Loss:  0.0\n",
            "Index 1120 - Loss:  0.0\n",
            "Index 1130 - Loss:  0.0\n",
            "Index 1140 - Loss:  0.0\n",
            "Index 1150 - Loss:  0.0\n",
            "Index 1160 - Loss:  0.0\n",
            "Index 1170 - Loss:  1.4305104514278355e-06\n",
            "Index 1180 - Loss:  0.0\n",
            "Index 1190 - Loss:  0.0\n",
            "Index 1200 - Loss:  0.0\n",
            "Index 1210 - Loss:  0.0\n",
            "Index 1220 - Loss:  0.0\n",
            "Index 1230 - Loss:  0.0\n",
            "Index 1240 - Loss:  0.0\n",
            "Index 1250 - Loss:  0.0\n",
            "Index 1260 - Loss:  0.008138233795762062\n",
            "Index 1270 - Loss:  12.225537300109863\n",
            "Index 1280 - Loss:  0.0\n",
            "Index 1290 - Loss:  0.0\n",
            "Index 1300 - Loss:  0.0\n",
            "Index 1310 - Loss:  0.0\n",
            "Index 1320 - Loss:  0.0\n",
            "Index 1330 - Loss:  0.0\n",
            "Index 1340 - Loss:  0.001053969725035131\n",
            "Index 1350 - Loss:  0.0\n",
            "Index 1360 - Loss:  0.0\n",
            "Index 1370 - Loss:  0.0\n",
            "Index 1380 - Loss:  0.0\n",
            "Index 1390 - Loss:  0.0\n",
            "Index 1400 - Loss:  33.990116119384766\n",
            "Index 1410 - Loss:  0.0\n",
            "Index 1420 - Loss:  1.1920928244535389e-07\n",
            "Index 1430 - Loss:  3.2186455882765586e-06\n",
            "Index 1440 - Loss:  0.0\n",
            "Index 1450 - Loss:  0.0\n",
            "Index 1460 - Loss:  0.0\n",
            "Index 1470 - Loss:  8.344646857949556e-07\n",
            "Index 1480 - Loss:  2.3841855067985307e-07\n",
            "Index 1490 - Loss:  0.0\n",
            "Index 1500 - Loss:  0.0\n",
            "Index 1510 - Loss:  0.006199652794748545\n",
            "Index 1520 - Loss:  0.0015706595731899142\n",
            "Index 1530 - Loss:  0.0\n",
            "Index 1540 - Loss:  0.0\n",
            "Index 1550 - Loss:  0.0\n",
            "Index 1560 - Loss:  0.0\n",
            "Index 1570 - Loss:  0.0\n",
            "Index 1580 - Loss:  2.3841855067985307e-07\n",
            "Index 1590 - Loss:  0.0\n",
            "Index 1600 - Loss:  0.0\n",
            "Index 1610 - Loss:  0.0\n",
            "Index 1620 - Loss:  0.0\n",
            "Index 1630 - Loss:  0.0\n",
            "Index 1640 - Loss:  0.0\n",
            "Index 1650 - Loss:  0.0\n",
            "Index 1660 - Loss:  0.0\n",
            "Index 1670 - Loss:  0.0\n",
            "Index 1680 - Loss:  0.0\n",
            "Index 1690 - Loss:  1.0728830375228426e-06\n",
            "Index 1700 - Loss:  0.0\n",
            "Index 1710 - Loss:  0.0\n",
            "Index 1720 - Loss:  14.021932601928711\n",
            "Index 1730 - Loss:  0.0\n",
            "Index 1740 - Loss:  0.0\n",
            "Index 1750 - Loss:  0.0\n",
            "Index 1760 - Loss:  0.0\n",
            "Index 1770 - Loss:  0.0\n",
            "Index 1780 - Loss:  0.0\n",
            "Index 1790 - Loss:  0.006484420038759708\n",
            "Index 1800 - Loss:  0.0\n",
            "Index 1810 - Loss:  0.0\n",
            "Index 1820 - Loss:  0.0\n",
            "Index 1830 - Loss:  0.0\n",
            "Index 1840 - Loss:  0.0\n",
            "Index 1850 - Loss:  0.0\n",
            "Index 1860 - Loss:  0.0\n",
            "Index 1870 - Loss:  1.1920928244535389e-07\n",
            "Index 1880 - Loss:  0.0\n",
            "Index 1890 - Loss:  0.0\n",
            "Index 1900 - Loss:  0.0\n",
            "Index 1910 - Loss:  0.0\n",
            "Index 1920 - Loss:  0.0\n",
            "Index 1930 - Loss:  0.0\n",
            "Index 1940 - Loss:  0.0\n",
            "Index 1950 - Loss:  0.0\n",
            "Index 1960 - Loss:  20.417219161987305\n",
            "Index 1970 - Loss:  0.0\n",
            "Index 1980 - Loss:  0.0\n",
            "Index 1990 - Loss:  0.0\n",
            "Index 2000 - Loss:  4.6491513785440475e-06\n",
            "Index 2010 - Loss:  0.0\n",
            "Index 2020 - Loss:  0.0\n",
            "Index 2030 - Loss:  0.9771057367324829\n",
            "Index 2040 - Loss:  56.425880432128906\n",
            "Index 2050 - Loss:  1.4543427823809907e-05\n",
            "Index 2060 - Loss:  0.0\n",
            "Index 2070 - Loss:  0.0\n",
            "Index 2080 - Loss:  0.000800408364739269\n",
            "Index 2090 - Loss:  0.00020430385484360158\n",
            "Index 2100 - Loss:  0.0\n",
            "Index 2110 - Loss:  0.0\n",
            "Index 2120 - Loss:  107.80868530273438\n",
            "Index 2130 - Loss:  2.7418097943154862e-06\n",
            "Index 2140 - Loss:  0.0\n",
            "Index 2150 - Loss:  0.0\n",
            "Index 2160 - Loss:  0.0021755853667855263\n",
            "Index 2170 - Loss:  4.291525328881107e-06\n",
            "Index 2180 - Loss:  0.0\n",
            "Index 2190 - Loss:  3.814689989667386e-06\n",
            "Index 2200 - Loss:  0.0\n",
            "Index 2210 - Loss:  0.0\n",
            "Index 2220 - Loss:  0.0015286438865587115\n",
            "Index 2230 - Loss:  0.0\n",
            "Index 2240 - Loss:  1.1920928244535389e-07\n",
            "Index 2250 - Loss:  0.0\n",
            "Index 2260 - Loss:  0.0\n",
            "Index 2270 - Loss:  0.6143330931663513\n",
            "Index 2280 - Loss:  0.0\n",
            "Index 2290 - Loss:  0.0\n",
            "Index 2300 - Loss:  0.13244415819644928\n",
            "Index 2310 - Loss:  0.0\n",
            "Index 2320 - Loss:  0.003456809790804982\n",
            "Index 2330 - Loss:  0.0\n",
            "Index 2340 - Loss:  3.981510963058099e-05\n",
            "Index 2350 - Loss:  0.0\n",
            "Index 2360 - Loss:  0.0\n",
            "Index 2370 - Loss:  0.0003116837178822607\n",
            "Index 2380 - Loss:  0.0\n",
            "Index 2390 - Loss:  16.33917236328125\n",
            "Index 2400 - Loss:  0.0\n",
            "Index 2410 - Loss:  0.0\n",
            "Index 2420 - Loss:  0.000263894529780373\n",
            "Index 2430 - Loss:  0.0022061550989747047\n",
            "Index 2440 - Loss:  0.0\n",
            "Index 2450 - Loss:  0.006800956558436155\n",
            "Index 2460 - Loss:  0.0\n",
            "Index 2470 - Loss:  0.0\n",
            "Index 2480 - Loss:  0.0\n",
            "Index 2490 - Loss:  0.0\n",
            "Index 2500 - Loss:  0.0\n",
            "Index 2510 - Loss:  2.193188190460205\n",
            "Index 2520 - Loss:  0.0\n",
            "Index 2530 - Loss:  0.10513963550329208\n",
            "Index 2540 - Loss:  0.0\n",
            "Index 2550 - Loss:  0.0\n",
            "Index 2560 - Loss:  0.007771139964461327\n",
            "Index 2570 - Loss:  0.5441911220550537\n",
            "Index 2580 - Loss:  0.0\n",
            "Index 2590 - Loss:  4.1126360883936286e-05\n",
            "Index 2600 - Loss:  3.814689989667386e-06\n",
            "Index 2610 - Loss:  2.1219027985353023e-05\n",
            "Index 2620 - Loss:  0.0\n",
            "Index 2630 - Loss:  0.0\n",
            "Index 2640 - Loss:  0.0\n",
            "Index 2650 - Loss:  0.0\n",
            "Index 2660 - Loss:  0.0\n",
            "Index 2670 - Loss:  0.0\n",
            "Index 2680 - Loss:  1.5944732427597046\n",
            "Index 2690 - Loss:  0.0884176641702652\n",
            "Index 2700 - Loss:  0.28159934282302856\n",
            "Index 2710 - Loss:  0.0\n",
            "Index 2720 - Loss:  0.002630228642374277\n",
            "Index 2730 - Loss:  0.47870004177093506\n",
            "Index 2740 - Loss:  0.0\n",
            "Index 2750 - Loss:  0.0\n",
            "Index 2760 - Loss:  9.536738616588991e-07\n",
            "Index 2770 - Loss:  9.665079116821289\n",
            "Index 2780 - Loss:  47.10359191894531\n",
            "Index 2790 - Loss:  0.0\n",
            "Index 2800 - Loss:  11.58842658996582\n",
            "Index 2810 - Loss:  0.2548850178718567\n",
            "Index 2820 - Loss:  0.0025078770704567432\n",
            "Index 2830 - Loss:  8.725739462533966e-05\n",
            "Index 2840 - Loss:  1.7410184144973755\n",
            "Index 2850 - Loss:  0.0\n",
            "Index 2860 - Loss:  0.0\n",
            "Index 2870 - Loss:  0.0\n",
            "Index 2880 - Loss:  0.0\n",
            "Index 2890 - Loss:  0.0\n",
            "Index 2900 - Loss:  2.373478651046753\n",
            "Index 2910 - Loss:  9.047575440490618e-05\n",
            "Index 2920 - Loss:  0.00928110908716917\n",
            "Index 2930 - Loss:  1.7589411735534668\n",
            "Index 2940 - Loss:  0.0\n",
            "Index 2950 - Loss:  2.1368408203125\n",
            "Index 2960 - Loss:  0.0\n",
            "Index 2970 - Loss:  2.4418516159057617\n",
            "Index 2980 - Loss:  0.003604345954954624\n",
            "Index 2990 - Loss:  0.014486964792013168\n",
            "Index 3000 - Loss:  1.6227022409439087\n",
            "Index 3010 - Loss:  0.00024184639914892614\n",
            "Index 3020 - Loss:  0.015579655766487122\n",
            "Index 3030 - Loss:  1.572447657585144\n",
            "Index 3040 - Loss:  0.0\n",
            "Index 3050 - Loss:  1.9073468138230965e-06\n",
            "Index 3060 - Loss:  0.00415426678955555\n",
            "Index 3070 - Loss:  1.5497195136049413e-06\n",
            "Index 3080 - Loss:  0.0\n",
            "Index 3090 - Loss:  0.2641237676143646\n",
            "Index 3100 - Loss:  1.5788931846618652\n",
            "Index 3110 - Loss:  0.0\n",
            "Index 3120 - Loss:  0.0\n",
            "Index 3130 - Loss:  0.0\n",
            "Index 3140 - Loss:  1.524582028388977\n",
            "Index 3150 - Loss:  2.037655830383301\n",
            "Index 3160 - Loss:  1.511663556098938\n",
            "Index 3170 - Loss:  1.6689286894688848e-06\n",
            "Index 3180 - Loss:  0.0\n",
            "Index 3190 - Loss:  2.3841855067985307e-07\n",
            "Index 3200 - Loss:  0.012446820735931396\n",
            "Index 3210 - Loss:  0.0\n",
            "Index 3220 - Loss:  1.764281842042692e-05\n",
            "Index 3230 - Loss:  0.014734495431184769\n",
            "Index 3240 - Loss:  0.0\n",
            "Index 3250 - Loss:  0.0\n",
            "Index 3260 - Loss:  0.0\n",
            "Index 3270 - Loss:  0.0\n",
            "Index 3280 - Loss:  0.0\n",
            "Index 3290 - Loss:  0.0\n",
            "Index 3300 - Loss:  0.0\n",
            "Index 3310 - Loss:  2.0435214042663574\n",
            "Index 3320 - Loss:  0.001800346071831882\n",
            "Index 3330 - Loss:  0.0\n",
            "Index 3340 - Loss:  1.1920928244535389e-07\n",
            "Index 3350 - Loss:  0.002273952355608344\n",
            "Index 3360 - Loss:  4.896141052246094\n",
            "Index 3370 - Loss:  0.0\n",
            "Index 3380 - Loss:  0.0\n",
            "Index 3390 - Loss:  2.0251340866088867\n",
            "Index 3400 - Loss:  2.2291887944447808e-05\n",
            "Index 3410 - Loss:  1.265267014503479\n",
            "Index 3420 - Loss:  2.130282163619995\n",
            "Index 3430 - Loss:  4.410734163684538e-06\n",
            "Index 3440 - Loss:  0.0\n",
            "Index 3450 - Loss:  1.220674991607666\n",
            "Index 3460 - Loss:  2.0563957691192627\n",
            "Index 3470 - Loss:  0.6727358102798462\n",
            "Index 3480 - Loss:  1.549708758830093e-05\n",
            "Index 3490 - Loss:  0.0\n",
            "Index 3500 - Loss:  0.0\n",
            "Index 3510 - Loss:  0.006246922072023153\n",
            "Index 3520 - Loss:  0.0\n",
            "Index 3530 - Loss:  1.1801649634435307e-05\n",
            "Index 3540 - Loss:  0.0\n",
            "Index 3550 - Loss:  1.728519782773219e-05\n",
            "Index 3560 - Loss:  0.00018690270371735096\n",
            "Index 3570 - Loss:  0.0\n",
            "Index 3580 - Loss:  1.150007963180542\n",
            "Index 3590 - Loss:  0.0\n",
            "Index 3600 - Loss:  0.0007435894221998751\n",
            "Index 3610 - Loss:  0.0\n",
            "Index 3620 - Loss:  0.07357688248157501\n",
            "Index 3630 - Loss:  0.022766290232539177\n",
            "Index 3640 - Loss:  1.8765490055084229\n",
            "Index 3650 - Loss:  0.0\n",
            "Index 3660 - Loss:  0.0\n",
            "Index 3670 - Loss:  0.0\n",
            "Index 3680 - Loss:  0.0\n",
            "Index 3690 - Loss:  0.0\n",
            "Index 3700 - Loss:  0.0\n",
            "Index 3710 - Loss:  2.027523994445801\n",
            "Index 3720 - Loss:  0.0\n",
            "Index 3730 - Loss:  1.0209193229675293\n",
            "Index 3740 - Loss:  0.0\n",
            "Index 3750 - Loss:  1.9249095916748047\n",
            "Index 3760 - Loss:  0.0\n",
            "Index 3770 - Loss:  0.0\n",
            "Index 3780 - Loss:  1.841896414756775\n",
            "Index 3790 - Loss:  0.0\n",
            "Index 3800 - Loss:  0.00010179955279454589\n",
            "Index 3810 - Loss:  0.0\n",
            "Index 3820 - Loss:  0.0038100522942841053\n",
            "Index 3830 - Loss:  3.576272320060525e-06\n",
            "Index 3840 - Loss:  0.0\n",
            "Index 3850 - Loss:  0.0\n",
            "Index 3860 - Loss:  61.475162506103516\n",
            "Index 3870 - Loss:  0.20822317898273468\n",
            "Index 3880 - Loss:  0.9914109110832214\n",
            "Index 3890 - Loss:  1.7242780923843384\n",
            "Index 3900 - Loss:  3.2518346309661865\n",
            "Index 3910 - Loss:  2.0146166207268834e-05\n",
            "Index 3920 - Loss:  1.718717336654663\n",
            "Index 3930 - Loss:  0.0\n",
            "Index 3940 - Loss:  0.9940973520278931\n",
            "Index 3950 - Loss:  2.0966007709503174\n",
            "Index 3960 - Loss:  0.0\n",
            "Index 3970 - Loss:  2.070380449295044\n",
            "Index 3980 - Loss:  0.000942858459893614\n",
            "Index 3990 - Loss:  2.023026466369629\n",
            "Index 4000 - Loss:  1.8954096958623268e-05\n",
            "Index 4010 - Loss:  1.0101902484893799\n",
            "Index 4020 - Loss:  0.0003150205302517861\n",
            "Index 4030 - Loss:  0.00032240914879366755\n",
            "Index 4040 - Loss:  2.6417689323425293\n",
            "Index 4050 - Loss:  0.0\n",
            "Index 4060 - Loss:  0.001854725182056427\n",
            "Index 4070 - Loss:  1.030669093132019\n",
            "Index 4080 - Loss:  0.0014761515194550157\n",
            "Index 4090 - Loss:  0.0003389737685211003\n",
            "Index 4100 - Loss:  8.106172561645508\n",
            "Index 4110 - Loss:  0.0\n",
            "Index 4120 - Loss:  1.8611863851547241\n",
            "Index 4130 - Loss:  1.7228347063064575\n",
            "Index 4140 - Loss:  1.7203329801559448\n",
            "Index 4150 - Loss:  0.0\n",
            "Index 4160 - Loss:  1.7006120681762695\n",
            "Index 4170 - Loss:  1.1920928244535389e-07\n",
            "Index 4180 - Loss:  2.9769434928894043\n",
            "Index 4190 - Loss:  0.0\n",
            "Index 4200 - Loss:  2.9672036170959473\n",
            "Index 4210 - Loss:  1.0592163801193237\n",
            "Index 4220 - Loss:  0.0\n",
            "Index 4230 - Loss:  2.912184715270996\n",
            "Index 4240 - Loss:  2.835568904876709\n",
            "Index 4250 - Loss:  1.0863136053085327\n",
            "Index 4260 - Loss:  2.783515453338623\n",
            "Index 4270 - Loss:  1.098855972290039\n",
            "Index 4280 - Loss:  2.7218732833862305\n",
            "Index 4290 - Loss:  1.7081153392791748\n",
            "Index 4300 - Loss:  1.7198373079299927\n",
            "Index 4310 - Loss:  2.6606526374816895\n",
            "Index 4320 - Loss:  2.6182711124420166\n",
            "Index 4330 - Loss:  2.671177864074707\n",
            "Index 4340 - Loss:  1.6894803047180176\n",
            "Index 4350 - Loss:  0.0\n",
            "Index 4360 - Loss:  1.6951428651809692\n",
            "Index 4370 - Loss:  2.5108954906463623\n",
            "Index 4380 - Loss:  0.0\n",
            "Index 4390 - Loss:  0.0\n",
            "Index 4400 - Loss:  2.4825706481933594\n",
            "Index 4410 - Loss:  2.5239360332489014\n",
            "Index 4420 - Loss:  1.3337697982788086\n",
            "Index 4430 - Loss:  1.6525611877441406\n",
            "Index 4440 - Loss:  1.6666544675827026\n",
            "Index 4450 - Loss:  8.672759056091309\n",
            "Index 4460 - Loss:  2.4373228549957275\n",
            "Index 4470 - Loss:  2.4425606727600098\n",
            "Index 4480 - Loss:  1.6569360494613647\n",
            "Index 4490 - Loss:  0.06732842326164246\n",
            "Index 4500 - Loss:  1.3773530721664429\n",
            "Index 4510 - Loss:  2.403923511505127\n",
            "Index 4520 - Loss:  1.5950671434402466\n",
            "Index 4530 - Loss:  1.3916739225387573\n",
            "Index 4540 - Loss:  1.3991296291351318\n",
            "Index 4550 - Loss:  0.0002579356369096786\n",
            "Index 4560 - Loss:  2.3553733825683594\n",
            "Index 4570 - Loss:  1.4005608558654785\n",
            "Index 4580 - Loss:  146.26882934570312\n",
            "Index 4590 - Loss:  1.3995511531829834\n",
            "Index 4600 - Loss:  2.307966709136963\n",
            "Index 4610 - Loss:  2.322270631790161\n",
            "Index 4620 - Loss:  2.282647132873535\n",
            "Index 4630 - Loss:  1.422431468963623\n",
            "Index 4640 - Loss:  2.480088710784912\n",
            "Index 4650 - Loss:  1.4230555295944214\n",
            "Index 4660 - Loss:  1.5544856786727905\n",
            "Index 4670 - Loss:  2.2398478984832764\n",
            "Index 4680 - Loss:  2.285576581954956\n",
            "Index 4690 - Loss:  0.0\n",
            "Index 4700 - Loss:  1.562072992324829\n",
            "Index 4710 - Loss:  1.5607846975326538\n",
            "Index 4720 - Loss:  1.5562078952789307\n",
            "Index 4730 - Loss:  2.3870739936828613\n",
            "Index 4740 - Loss:  2.3750550746917725\n",
            "Index 4750 - Loss:  2.1591367721557617\n",
            "Index 4760 - Loss:  1.773761510848999\n",
            "Index 4770 - Loss:  1.5808933973312378\n",
            "Index 4780 - Loss:  2.2866344451904297\n",
            "Index 4790 - Loss:  1.5754591226577759\n",
            "Index 4800 - Loss:  2.3469784259796143\n",
            "Index 4810 - Loss:  0.0\n",
            "Index 4820 - Loss:  2.332432508468628\n",
            "Index 4830 - Loss:  1.4806147813796997\n",
            "Index 4840 - Loss:  1.4717143774032593\n",
            "Index 4850 - Loss:  1.4699902534484863\n",
            "Index 4860 - Loss:  2.3232202529907227\n",
            "Index 4870 - Loss:  0.0\n",
            "Index 4880 - Loss:  2.317477226257324\n",
            "Index 4890 - Loss:  1.6046268939971924\n",
            "Index 4900 - Loss:  1.4665125608444214\n",
            "Index 4910 - Loss:  2.0835607051849365\n",
            "Index 4920 - Loss:  2.311347484588623\n",
            "Index 4930 - Loss:  2.1620583534240723\n",
            "Index 4940 - Loss:  2.155332088470459\n",
            "Index 4950 - Loss:  1.624048113822937\n",
            "Index 4960 - Loss:  1.6218072175979614\n",
            "Index 4970 - Loss:  2.1486780643463135\n",
            "Index 4980 - Loss:  2.032555103302002\n",
            "Index 4990 - Loss:  2.0180439949035645\n",
            "Index 5000 - Loss:  1.6333640813827515\n",
            "Index 5010 - Loss:  1.6358119249343872\n",
            "Index 5020 - Loss:  2.0080108642578125\n",
            "Index 5030 - Loss:  2.23620343208313\n",
            "Index 5040 - Loss:  2.222743034362793\n",
            "Index 5050 - Loss:  2.018660545349121\n",
            "Index 5060 - Loss:  2.0182626247406006\n",
            "Index 5070 - Loss:  1.6582512855529785\n",
            "Index 5080 - Loss:  2.1874351501464844\n",
            "Index 5090 - Loss:  1.9727885723114014\n",
            "Index 5100 - Loss:  1.8419232368469238\n",
            "Index 5110 - Loss:  1.9513654708862305\n",
            "Index 5120 - Loss:  2.195383071899414\n",
            "Index 5130 - Loss:  1.838612675666809\n",
            "Index 5140 - Loss:  1.929796814918518\n",
            "Index 5150 - Loss:  2.2052016258239746\n",
            "Index 5160 - Loss:  1.9109212160110474\n",
            "Index 5170 - Loss:  2.0033950805664062\n",
            "Index 5180 - Loss:  1.8935354948043823\n",
            "Index 5190 - Loss:  0.0\n",
            "Index 5200 - Loss:  1.7297343015670776\n",
            "Index 5210 - Loss:  1.872501254081726\n",
            "Index 5220 - Loss:  1.8559277057647705\n",
            "Index 5230 - Loss:  0.0\n",
            "Index 5240 - Loss:  1.8460474014282227\n",
            "Index 5250 - Loss:  1.9232995510101318\n",
            "Index 5260 - Loss:  0.0\n",
            "Index 5270 - Loss:  1.672376036643982\n",
            "Index 5280 - Loss:  2.0061278343200684\n",
            "Index 5290 - Loss:  1.6642670631408691\n",
            "Index 5300 - Loss:  1.9259302616119385\n",
            "Index 5310 - Loss:  1.6678705215454102\n",
            "Index 5320 - Loss:  1.8160299062728882\n",
            "Index 5330 - Loss:  1.8068674802780151\n",
            "Index 5340 - Loss:  2.001836061477661\n",
            "Index 5350 - Loss:  1.6561412811279297\n",
            "Index 5360 - Loss:  1.7893918752670288\n",
            "Index 5370 - Loss:  2.1599855422973633\n",
            "Index 5380 - Loss:  0.0\n",
            "Index 5390 - Loss:  1.6847202777862549\n",
            "Index 5400 - Loss:  0.0\n",
            "Index 5410 - Loss:  0.0\n",
            "Index 5420 - Loss:  0.0\n",
            "Index 5430 - Loss:  1.8662850856781006\n",
            "Index 5440 - Loss:  1.6972403526306152\n",
            "Index 5450 - Loss:  1.7275398969650269\n",
            "Index 5460 - Loss:  1.9653013944625854\n",
            "Index 5470 - Loss:  0.0\n",
            "Index 5480 - Loss:  3.974257707595825\n",
            "Index 5490 - Loss:  1.6921013593673706\n",
            "Index 5500 - Loss:  1.690136432647705\n",
            "Index 5510 - Loss:  1.6876816749572754\n",
            "Index 5520 - Loss:  0.0\n",
            "Index 5530 - Loss:  2.111436367034912\n",
            "Index 5540 - Loss:  1.7393758296966553\n",
            "Index 5550 - Loss:  2.0968499183654785\n",
            "Index 5560 - Loss:  1.782297134399414\n",
            "Index 5570 - Loss:  2.081777334213257\n",
            "Index 5580 - Loss:  2.067445755004883\n",
            "Index 5590 - Loss:  1.7203987836837769\n",
            "Index 5600 - Loss:  1.7273664474487305\n",
            "Index 5610 - Loss:  1.8660860061645508\n",
            "Index 5620 - Loss:  1.7553690671920776\n",
            "Index 5630 - Loss:  1.744248390197754\n",
            "Index 5640 - Loss:  1.7399722337722778\n",
            "Index 5650 - Loss:  1.9316173791885376\n",
            "Index 5660 - Loss:  1.869446873664856\n",
            "Index 5670 - Loss:  0.0\n",
            "Index 5680 - Loss:  2.0639078617095947\n",
            "Index 5690 - Loss:  1.768202781677246\n",
            "Index 5700 - Loss:  1.77315354347229\n",
            "Index 5710 - Loss:  1.8776066303253174\n",
            "Index 5720 - Loss:  0.0\n",
            "Index 5730 - Loss:  1.7373418807983398\n",
            "Index 5740 - Loss:  1.8598918914794922\n",
            "Index 5750 - Loss:  1.7442028522491455\n",
            "Index 5760 - Loss:  1.9186898469924927\n",
            "Index 5770 - Loss:  1.7365484237670898\n",
            "Index 5780 - Loss:  1.740929126739502\n",
            "Index 5790 - Loss:  1.7347952127456665\n",
            "Index 5800 - Loss:  1.7304071187973022\n",
            "Index 5810 - Loss:  0.0\n",
            "Index 5820 - Loss:  1.919669508934021\n",
            "Index 5830 - Loss:  1.8838675022125244\n",
            "Index 5840 - Loss:  1.9050743579864502\n",
            "Index 5850 - Loss:  2.0017714500427246\n",
            "Index 5860 - Loss:  1.8583958148956299\n",
            "Index 5870 - Loss:  1.7924827337265015\n",
            "Index 5880 - Loss:  0.0\n",
            "Index 5890 - Loss:  1.786379337310791\n",
            "Index 5900 - Loss:  1.7763519287109375\n",
            "Index 5910 - Loss:  1.7762908935546875\n",
            "Index 5920 - Loss:  1.773316502571106\n",
            "Index 5930 - Loss:  1.7621108293533325\n",
            "Index 5940 - Loss:  1.7722880840301514\n",
            "Index 5950 - Loss:  1.8962585926055908\n",
            "Index 5960 - Loss:  1.8834624290466309\n",
            "Index 5970 - Loss:  0.0\n",
            "Index 5980 - Loss:  1.8829232454299927\n",
            "Index 5990 - Loss:  1.7957899570465088\n",
            "Index 6000 - Loss:  1.971551775932312\n",
            "Index 6010 - Loss:  1.9626340866088867\n",
            "Index 6020 - Loss:  1.9568090438842773\n",
            "Index 6030 - Loss:  0.0\n",
            "Index 6040 - Loss:  1.9319813251495361\n",
            "Index 6050 - Loss:  4.240396499633789\n",
            "Index 6060 - Loss:  1.838422417640686\n",
            "Index 6070 - Loss:  1.0728830375228426e-06\n",
            "Index 6080 - Loss:  1.910738468170166\n",
            "Index 6090 - Loss:  1.8870092630386353\n",
            "Index 6100 - Loss:  1.8120617866516113\n",
            "Index 6110 - Loss:  1.8568029403686523\n",
            "Index 6120 - Loss:  1.8499200344085693\n",
            "Index 6130 - Loss:  1.8042469024658203\n",
            "Index 6140 - Loss:  0.0\n",
            "Index 6150 - Loss:  1.8121864795684814\n",
            "Index 6160 - Loss:  1.871103286743164\n",
            "Index 6170 - Loss:  1.8071868419647217\n",
            "Index 6180 - Loss:  1.8489367961883545\n",
            "Index 6190 - Loss:  1.861681342124939\n",
            "Index 6200 - Loss:  1.856162667274475\n",
            "Index 6210 - Loss:  1.8724006414413452\n",
            "Index 6220 - Loss:  1.8006083965301514\n",
            "Index 6230 - Loss:  1.8571124076843262\n",
            "Index 6240 - Loss:  1.8044490814208984\n",
            "Index 6250 - Loss:  4.327835559844971\n",
            "Index 6260 - Loss:  1.8578964471817017\n",
            "Index 6270 - Loss:  1.8443716764450073\n",
            "Index 6280 - Loss:  1.8222569227218628\n",
            "Index 6290 - Loss:  1.8482792377471924\n",
            "Index 6300 - Loss:  1.8571058511734009\n",
            "Index 6310 - Loss:  1.8552333116531372\n",
            "Index 6320 - Loss:  1.8548005819320679\n",
            "Index 6330 - Loss:  1.8241502046585083\n",
            "Index 6340 - Loss:  1.7926080226898193\n",
            "Index 6350 - Loss:  1.7845934629440308\n",
            "Index 6360 - Loss:  1.8550970554351807\n",
            "Index 6370 - Loss:  1.8766839504241943\n",
            "Index 6380 - Loss:  1.8412257432937622\n",
            "Index 6390 - Loss:  1.8379132747650146\n",
            "Index 6400 - Loss:  1.8731799125671387\n",
            "Index 6410 - Loss:  1.8245398998260498\n",
            "Index 6420 - Loss:  1.8487374782562256\n",
            "Index 6430 - Loss:  1.8427804708480835\n",
            "Index 6440 - Loss:  1.8145620822906494\n",
            "Index 6450 - Loss:  1.8190518617630005\n",
            "Index 6460 - Loss:  1.9160726070404053\n",
            "Index 6470 - Loss:  1.8190357685089111\n",
            "Index 6480 - Loss:  1.812249779701233\n",
            "Index 6490 - Loss:  1.8717832565307617\n",
            "Index 6500 - Loss:  1.8480379581451416\n",
            "Index 6510 - Loss:  0.0\n",
            "Index 6520 - Loss:  1.8361881971359253\n",
            "Index 6530 - Loss:  1.907124638557434\n",
            "Index 6540 - Loss:  1.9062248468399048\n",
            "Index 6550 - Loss:  1.7617660760879517\n",
            "Index 6560 - Loss:  1.8372085094451904\n",
            "Index 6570 - Loss:  1.8340604305267334\n",
            "Index 6580 - Loss:  1.722857117652893\n",
            "Index 6590 - Loss:  1.9136238098144531\n",
            "Index 6600 - Loss:  1.9179588556289673\n",
            "Index 6610 - Loss:  1.8957629203796387\n",
            "Index 6620 - Loss:  1.8411812782287598\n",
            "Index 6630 - Loss:  1.7856518030166626\n",
            "Index 6640 - Loss:  4.09704065322876\n",
            "Index 6650 - Loss:  1.8634511232376099\n",
            "Index 6660 - Loss:  1.7234723567962646\n",
            "Index 6670 - Loss:  1.807094931602478\n",
            "Index 6680 - Loss:  1.8074182271957397\n",
            "Index 6690 - Loss:  1.7434759140014648\n",
            "Index 6700 - Loss:  1.796369194984436\n",
            "Index 6710 - Loss:  4.009986877441406\n",
            "Index 6720 - Loss:  1.7633658647537231\n",
            "Index 6730 - Loss:  1.8361124992370605\n",
            "Index 6740 - Loss:  1.8280041217803955\n",
            "Index 6750 - Loss:  1.9236087799072266\n",
            "Index 6760 - Loss:  1.8161171674728394\n",
            "Index 6770 - Loss:  1.7952309846878052\n",
            "Index 6780 - Loss:  1.9281220436096191\n",
            "Index 6790 - Loss:  1.837186336517334\n",
            "Index 6800 - Loss:  1.8347430229187012\n",
            "Index 6810 - Loss:  1.7837276458740234\n",
            "Index 6820 - Loss:  1.8312437534332275\n",
            "Index 6830 - Loss:  1.8041774034500122\n",
            "Index 6840 - Loss:  1.804032325744629\n",
            "Index 6850 - Loss:  0.0\n",
            "Index 6860 - Loss:  1.7897636890411377\n",
            "Index 6870 - Loss:  1.782481074333191\n",
            "Index 6880 - Loss:  1.8102887868881226\n",
            "Index 6890 - Loss:  1.8499844074249268\n",
            "Index 6900 - Loss:  1.7736306190490723\n",
            "Index 6910 - Loss:  1.8867158889770508\n",
            "Index 6920 - Loss:  6.472854875028133e-05\n",
            "Index 6930 - Loss:  1.8488355875015259\n",
            "Index 6940 - Loss:  1.8849899768829346\n",
            "Index 6950 - Loss:  1.8871163129806519\n",
            "Index 6960 - Loss:  1.8275079727172852\n",
            "Index 6970 - Loss:  1.79988694190979\n",
            "Index 6980 - Loss:  1.8272780179977417\n",
            "Index 6990 - Loss:  1.8282049894332886\n",
            "Index 7000 - Loss:  1.873354196548462\n",
            "Index 7010 - Loss:  1.8255144357681274\n",
            "Index 7020 - Loss:  1.8177827596664429\n",
            "Index 0 - Loss:  1.811211109161377\n",
            "Index 100 - Loss:  1.811211109161377\n",
            "Index 200 - Loss:  3.683258533477783\n",
            "Index 300 - Loss:  1.8624927997589111\n",
            "Index 400 - Loss:  1.8624927997589111\n",
            "Index 500 - Loss:  1.8624927997589111\n",
            "Index 600 - Loss:  1.8183709383010864\n",
            "Index 700 - Loss:  0.0\n",
            "Index 800 - Loss:  1.8183709383010864\n",
            "Index 900 - Loss:  1.811211109161377\n",
            "Index 1000 - Loss:  1.9442065954208374\n",
            "Index 1100 - Loss:  1.8624927997589111\n",
            "Index 1200 - Loss:  1.8624927997589111\n",
            "Index 1300 - Loss:  1.9442065954208374\n",
            "Index 1400 - Loss:  3.6834776401519775\n",
            "Index 1500 - Loss:  1.8183709383010864\n",
            "Index 1600 - Loss:  1.811211109161377\n",
            "Index 1700 - Loss:  1.811211109161377\n",
            "Index 1800 - Loss:  3.683258533477783\n",
            "Index 1900 - Loss:  0.021588917821645737\n",
            "Index 2000 - Loss:  1.8722292184829712\n",
            "Index 2100 - Loss:  3.683258533477783\n",
            "Index 2200 - Loss:  1.8183709383010864\n",
            "Index 2300 - Loss:  1.9442065954208374\n",
            "Index 2400 - Loss:  1.8183709383010864\n",
            "Index 2500 - Loss:  1.811211109161377\n",
            "Index 2600 - Loss:  1.9442065954208374\n",
            "Index 2700 - Loss:  1.9442065954208374\n",
            "Index 2800 - Loss:  1.8722292184829712\n",
            "Index 2900 - Loss:  1.9442065954208374\n",
            "Index 3000 - Loss:  1.9442065954208374\n",
            "Index 3100 - Loss:  1.9442065954208374\n",
            "Index 3200 - Loss:  1.8722292184829712\n",
            "Index 3300 - Loss:  0.003143371781334281\n",
            "Index 3400 - Loss:  1.811211109161377\n",
            "Index 3500 - Loss:  3.683258533477783\n",
            "Index 3600 - Loss:  1.8722292184829712\n",
            "Index 3700 - Loss:  0.0\n",
            "Index 3800 - Loss:  1.8722292184829712\n",
            "Index 3900 - Loss:  1.811211109161377\n",
            "Index 4000 - Loss:  1.8183709383010864\n",
            "Index 4100 - Loss:  1.811211109161377\n",
            "Index 4200 - Loss:  1.761357307434082\n",
            "Index 4300 - Loss:  1.8624927997589111\n",
            "Index 4400 - Loss:  1.8183709383010864\n",
            "Index 4500 - Loss:  1.9442065954208374\n",
            "Index 4600 - Loss:  1.811211109161377\n",
            "Index 4700 - Loss:  1.8624927997589111\n",
            "Index 4800 - Loss:  1.8183709383010864\n",
            "Index 4900 - Loss:  1.9442065954208374\n",
            "Index 5000 - Loss:  1.8624927997589111\n",
            "Index 5100 - Loss:  1.8722292184829712\n",
            "Index 5200 - Loss:  1.8624927997589111\n",
            "Index 5300 - Loss:  1.811211109161377\n",
            "Index 5400 - Loss:  0.0\n",
            "Index 5500 - Loss:  1.8624927997589111\n",
            "Index 5600 - Loss:  1.8624927997589111\n",
            "Index 5700 - Loss:  1.9442065954208374\n",
            "Index 5800 - Loss:  1.8722292184829712\n",
            "Index 5900 - Loss:  1.8624927997589111\n",
            "Index 6000 - Loss:  1.8183709383010864\n",
            "Index 6100 - Loss:  1.8624927997589111\n",
            "Index 6200 - Loss:  1.8183709383010864\n",
            "Index 6300 - Loss:  1.761357307434082\n",
            "Index 6400 - Loss:  1.8722292184829712\n",
            "Index 6500 - Loss:  1.761357307434082\n",
            "Index 6600 - Loss:  1.8722292184829712\n",
            "Index 6700 - Loss:  1.761357307434082\n",
            "Index 6800 - Loss:  1.761357307434082\n",
            "Index 6900 - Loss:  1.8183709383010864\n",
            "Index 7000 - Loss:  1.8624927997589111\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = MLP()\n",
        "\n",
        "# Fit function\n",
        "model.fit(X,y)\n",
        "\n",
        "# Training loop\n",
        "model.evaluate(X,y)\n",
        "\n",
        "# Get paramenters\n",
        "current_parameters = model.get_parameters()\n",
        "\n",
        "# Load paramenters\n",
        "model.load_parameters(current_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzvpCQDhVUBD"
      },
      "source": [
        "#Build generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfINZ2pTNhY6",
        "outputId": "68bf9238-6dea-416e-8671-797355a5235d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(n_epochs=1000, batch_size=1, lr=0.0001, b1=0.5, b2=0.999, n_cpu=8, latent_dim=8, features=28, channels=1, sample_interval=400)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=1000, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=1, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=8, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--features\", type=int, default=28, help=\"number of features\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
        "opt = parser.parse_args(args=[])\n",
        "print(opt)\n",
        "\n",
        "Tensor = torch.FloatTensor\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.features // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(num_labels*2, 128 * self.init_size))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(size = [1, self.init_size*2]),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(size = [1, self.init_size*4]),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "            )\n",
        "\n",
        "    def forward(self, label):\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (1, num_labels))), requires_grad=True)\n",
        "        out = self.l1(torch.cat((z, label), axis = 1))\n",
        "        out = out.view(1, 128, 1, self.init_size)\n",
        "        data = self.conv_blocks(out)\n",
        "        return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQLHT1ebjzl",
        "outputId": "197bc198-16bf-4fcb-8ed0-32dac64f7b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/1000], Loss: 1.8725881576538086\n",
            "Epoch [1/1000], Loss: 1.8119232654571533\n",
            "Epoch [2/1000], Loss: 1.8113248348236084\n",
            "Epoch [3/1000], Loss: 3.6828622817993164\n",
            "Epoch [4/1000], Loss: 3.6816930770874023\n",
            "Epoch [5/1000], Loss: 1.818269968032837\n",
            "Epoch [6/1000], Loss: 1.871913194656372\n",
            "Epoch [7/1000], Loss: 3.6840436458587646\n",
            "Epoch [8/1000], Loss: 1.8646107912063599\n",
            "Epoch [9/1000], Loss: 1.8072936534881592\n",
            "Epoch [10/1000], Loss: 1.8222085237503052\n",
            "Epoch [11/1000], Loss: 3.682880401611328\n",
            "Epoch [12/1000], Loss: 1.8623443841934204\n",
            "Epoch [13/1000], Loss: 3.686640739440918\n",
            "Epoch [14/1000], Loss: 1.9425687789916992\n",
            "Epoch [15/1000], Loss: 1.8622528314590454\n",
            "Epoch [16/1000], Loss: 1.862891674041748\n",
            "Epoch [17/1000], Loss: 1.8627406358718872\n",
            "Epoch [18/1000], Loss: 1.7610101699829102\n",
            "Epoch [19/1000], Loss: 1.7597185373306274\n",
            "Epoch [20/1000], Loss: 1.9413340091705322\n",
            "Epoch [21/1000], Loss: 1.8066779375076294\n",
            "Epoch [22/1000], Loss: 1.8726365566253662\n",
            "Epoch [23/1000], Loss: 1.8194559812545776\n",
            "Epoch [24/1000], Loss: 1.7617542743682861\n",
            "Epoch [25/1000], Loss: 1.8623801469802856\n",
            "Epoch [26/1000], Loss: 1.80959153175354\n",
            "Epoch [27/1000], Loss: 1.9436358213424683\n",
            "Epoch [28/1000], Loss: 1.8063435554504395\n",
            "Epoch [29/1000], Loss: 1.8720402717590332\n",
            "Epoch [30/1000], Loss: 1.811842441558838\n",
            "Epoch [31/1000], Loss: 1.8719030618667603\n",
            "Epoch [32/1000], Loss: 1.8197331428527832\n",
            "Epoch [33/1000], Loss: 1.8182590007781982\n",
            "Epoch [34/1000], Loss: 3.6845688819885254\n",
            "Epoch [35/1000], Loss: 1.9442065954208374\n",
            "Epoch [36/1000], Loss: 1.7614316940307617\n",
            "Epoch [37/1000], Loss: 1.7575095891952515\n",
            "Epoch [38/1000], Loss: 1.8720340728759766\n",
            "Epoch [39/1000], Loss: 1.810341238975525\n",
            "Epoch [40/1000], Loss: 1.8625081777572632\n",
            "Epoch [41/1000], Loss: 3.683347225189209\n",
            "Epoch [42/1000], Loss: 1.9435542821884155\n",
            "Epoch [43/1000], Loss: 1.8113880157470703\n",
            "Epoch [44/1000], Loss: 1.8095377683639526\n",
            "Epoch [45/1000], Loss: 1.818299651145935\n",
            "Epoch [46/1000], Loss: 3.6850781440734863\n",
            "Epoch [47/1000], Loss: 1.872449517250061\n",
            "Epoch [48/1000], Loss: 3.683872699737549\n",
            "Epoch [49/1000], Loss: 3.6917920112609863\n",
            "Epoch [50/1000], Loss: 1.8115112781524658\n",
            "Epoch [51/1000], Loss: 1.872127652168274\n",
            "Epoch [52/1000], Loss: 3.6848373413085938\n",
            "Epoch [53/1000], Loss: 1.8183408975601196\n",
            "Epoch [54/1000], Loss: 3.682839870452881\n",
            "Epoch [55/1000], Loss: 1.8623700141906738\n",
            "Epoch [56/1000], Loss: 3.6829612255096436\n",
            "Epoch [57/1000], Loss: 3.6834776401519775\n",
            "Epoch [58/1000], Loss: 3.6856870651245117\n",
            "Epoch [59/1000], Loss: 1.811516284942627\n",
            "Epoch [60/1000], Loss: 1.8739097118377686\n",
            "Epoch [61/1000], Loss: 1.7539068460464478\n",
            "Epoch [62/1000], Loss: 1.8183338642120361\n",
            "Epoch [63/1000], Loss: 1.8722224235534668\n",
            "Epoch [64/1000], Loss: 1.8624777793884277\n",
            "Epoch [65/1000], Loss: 1.8198662996292114\n",
            "Epoch [66/1000], Loss: 3.6830978393554688\n",
            "Epoch [67/1000], Loss: 1.8183118104934692\n",
            "Epoch [68/1000], Loss: 1.9438369274139404\n",
            "Epoch [69/1000], Loss: 3.683053493499756\n",
            "Epoch [70/1000], Loss: 1.7615734338760376\n",
            "Epoch [71/1000], Loss: 1.8769103288650513\n",
            "Epoch [72/1000], Loss: 1.8183709383010864\n",
            "Epoch [73/1000], Loss: 1.761357307434082\n",
            "Epoch [74/1000], Loss: 1.8625035285949707\n",
            "Epoch [75/1000], Loss: 3.6707217693328857\n",
            "Epoch [76/1000], Loss: 3.6835222244262695\n",
            "Epoch [77/1000], Loss: 1.7599612474441528\n",
            "Epoch [78/1000], Loss: 3.6832687854766846\n",
            "Epoch [79/1000], Loss: 1.9442065954208374\n",
            "Epoch [80/1000], Loss: 1.943881869316101\n",
            "Epoch [81/1000], Loss: 1.876362681388855\n",
            "Epoch [82/1000], Loss: 3.683258533477783\n",
            "Epoch [83/1000], Loss: 1.8112870454788208\n",
            "Epoch [84/1000], Loss: 1.942419171333313\n",
            "Epoch [85/1000], Loss: 1.7613933086395264\n",
            "Epoch [86/1000], Loss: 3.683682918548584\n",
            "Epoch [87/1000], Loss: 1.8182274103164673\n",
            "Epoch [88/1000], Loss: 3.680473566055298\n",
            "Epoch [89/1000], Loss: 1.7583553791046143\n",
            "Epoch [90/1000], Loss: 1.824566125869751\n",
            "Epoch [91/1000], Loss: 1.811211109161377\n",
            "Epoch [92/1000], Loss: 1.8640745878219604\n",
            "Epoch [93/1000], Loss: 1.8720033168792725\n",
            "Epoch [94/1000], Loss: 1.7607604265213013\n",
            "Epoch [95/1000], Loss: 3.685826301574707\n",
            "Epoch [96/1000], Loss: 1.8256291151046753\n",
            "Epoch [97/1000], Loss: 1.8181262016296387\n",
            "Epoch [98/1000], Loss: 1.871973991394043\n",
            "Epoch [99/1000], Loss: 1.8624659776687622\n",
            "Epoch [100/1000], Loss: 1.8182929754257202\n",
            "Epoch [101/1000], Loss: 3.6907739639282227\n",
            "Epoch [102/1000], Loss: 3.6864852905273438\n",
            "Epoch [103/1000], Loss: 1.7613880634307861\n",
            "Epoch [104/1000], Loss: 1.8722292184829712\n",
            "Epoch [105/1000], Loss: 3.6838793754577637\n",
            "Epoch [106/1000], Loss: 3.6833131313323975\n",
            "Epoch [107/1000], Loss: 1.944133996963501\n",
            "Epoch [108/1000], Loss: 1.8624942302703857\n",
            "Epoch [109/1000], Loss: 1.811211109161377\n",
            "Epoch [110/1000], Loss: 3.6828389167785645\n",
            "Epoch [111/1000], Loss: 3.6834776401519775\n",
            "Epoch [112/1000], Loss: 1.943220615386963\n",
            "Epoch [113/1000], Loss: 1.9431097507476807\n",
            "Epoch [114/1000], Loss: 3.6745519638061523\n",
            "Epoch [115/1000], Loss: 1.8722292184829712\n",
            "Epoch [116/1000], Loss: 1.8624927997589111\n",
            "Epoch [117/1000], Loss: 3.6832218170166016\n",
            "Epoch [118/1000], Loss: 3.683258533477783\n",
            "Epoch [119/1000], Loss: 1.8719838857650757\n",
            "Epoch [120/1000], Loss: 3.6832027435302734\n",
            "Epoch [121/1000], Loss: 1.8182790279388428\n",
            "Epoch [122/1000], Loss: 1.7613637447357178\n",
            "Epoch [123/1000], Loss: 1.8183064460754395\n",
            "Epoch [124/1000], Loss: 1.8183709383010864\n",
            "Epoch [125/1000], Loss: 1.7580578327178955\n",
            "Epoch [126/1000], Loss: 3.681063175201416\n",
            "Epoch [127/1000], Loss: 3.667646646499634\n",
            "Epoch [128/1000], Loss: 1.8180887699127197\n",
            "Epoch [129/1000], Loss: 1.8717948198318481\n",
            "Epoch [130/1000], Loss: 1.8063279390335083\n",
            "Epoch [131/1000], Loss: 3.6839537620544434\n",
            "Epoch [132/1000], Loss: 3.683427333831787\n",
            "Epoch [133/1000], Loss: 1.8721879720687866\n",
            "Epoch [134/1000], Loss: 3.6588616371154785\n",
            "Epoch [135/1000], Loss: 1.7517330646514893\n",
            "Epoch [136/1000], Loss: 1.8068389892578125\n",
            "Epoch [137/1000], Loss: 1.7614835500717163\n",
            "Epoch [138/1000], Loss: 3.6833395957946777\n",
            "Epoch [139/1000], Loss: 1.8653955459594727\n",
            "Epoch [140/1000], Loss: 3.6513307094573975\n",
            "Epoch [141/1000], Loss: 1.8807175159454346\n",
            "Epoch [142/1000], Loss: 1.8183207511901855\n",
            "Epoch [143/1000], Loss: 1.93617582321167\n",
            "Epoch [144/1000], Loss: 1.8065882921218872\n",
            "Epoch [145/1000], Loss: 1.8031423091888428\n",
            "Epoch [146/1000], Loss: 1.9340354204177856\n",
            "Epoch [147/1000], Loss: 1.9367977380752563\n",
            "Epoch [148/1000], Loss: 1.8045011758804321\n",
            "Epoch [149/1000], Loss: 1.7967439889907837\n",
            "Epoch [150/1000], Loss: 1.8101905584335327\n",
            "Epoch [151/1000], Loss: 3.575867176055908\n",
            "Epoch [152/1000], Loss: 3.4970550537109375\n",
            "Epoch [153/1000], Loss: 1.805402159690857\n",
            "Epoch [154/1000], Loss: 3.6823647022247314\n",
            "Epoch [155/1000], Loss: 3.484226703643799\n",
            "Epoch [156/1000], Loss: 1.7505314350128174\n",
            "Epoch [157/1000], Loss: 1.8646321296691895\n",
            "Epoch [158/1000], Loss: 3.3846302032470703\n",
            "Epoch [159/1000], Loss: 1.8824976682662964\n",
            "Epoch [160/1000], Loss: 3.700082778930664\n",
            "Epoch [161/1000], Loss: 1.8249731063842773\n",
            "Epoch [162/1000], Loss: 1.750071406364441\n",
            "Epoch [163/1000], Loss: 1.7974718809127808\n",
            "Epoch [164/1000], Loss: 1.75786292552948\n",
            "Epoch [165/1000], Loss: 3.692716121673584\n",
            "Epoch [166/1000], Loss: 1.9075937271118164\n",
            "Epoch [167/1000], Loss: 1.750487208366394\n",
            "Epoch [168/1000], Loss: 1.8181066513061523\n",
            "Epoch [169/1000], Loss: 1.7838730812072754\n",
            "Epoch [170/1000], Loss: 1.9554704427719116\n",
            "Epoch [171/1000], Loss: 1.9371718168258667\n",
            "Epoch [172/1000], Loss: 1.7503303289413452\n",
            "Epoch [173/1000], Loss: 1.8017430305480957\n",
            "Epoch [174/1000], Loss: 1.9357435703277588\n",
            "Epoch [175/1000], Loss: 3.3723254203796387\n",
            "Epoch [176/1000], Loss: 1.8133116960525513\n",
            "Epoch [177/1000], Loss: 1.8604949712753296\n",
            "Epoch [178/1000], Loss: 3.18743896484375\n",
            "Epoch [179/1000], Loss: 1.817360520362854\n",
            "Epoch [180/1000], Loss: 1.8679406642913818\n",
            "Epoch [181/1000], Loss: 1.7834181785583496\n",
            "Epoch [182/1000], Loss: 1.8503775596618652\n",
            "Epoch [183/1000], Loss: 3.6861019134521484\n",
            "Epoch [184/1000], Loss: 1.875261902809143\n",
            "Epoch [185/1000], Loss: 1.8590903282165527\n",
            "Epoch [186/1000], Loss: 1.8981655836105347\n",
            "Epoch [187/1000], Loss: 1.8017998933792114\n",
            "Epoch [188/1000], Loss: 1.8868311643600464\n",
            "Epoch [189/1000], Loss: 2.7774300575256348\n",
            "Epoch [190/1000], Loss: 1.7878576517105103\n",
            "Epoch [191/1000], Loss: 2.9640917778015137\n",
            "Epoch [192/1000], Loss: 1.8586117029190063\n",
            "Epoch [193/1000], Loss: 1.9130412340164185\n",
            "Epoch [194/1000], Loss: 1.7983312606811523\n",
            "Epoch [195/1000], Loss: 1.7818654775619507\n",
            "Epoch [196/1000], Loss: 1.7509657144546509\n",
            "Epoch [197/1000], Loss: 1.8177649974822998\n",
            "Epoch [198/1000], Loss: 1.8931570053100586\n",
            "Epoch [199/1000], Loss: 1.8252124786376953\n",
            "Epoch [200/1000], Loss: 2.0005385875701904\n",
            "Epoch [201/1000], Loss: 1.8712016344070435\n",
            "Epoch [202/1000], Loss: 1.793215036392212\n",
            "Epoch [203/1000], Loss: 1.7868597507476807\n",
            "Epoch [204/1000], Loss: 2.0234549045562744\n",
            "Epoch [205/1000], Loss: 1.7526569366455078\n",
            "Epoch [206/1000], Loss: 3.6834776401519775\n",
            "Epoch [207/1000], Loss: 1.875780701637268\n",
            "Epoch [208/1000], Loss: 1.8722292184829712\n",
            "Epoch [209/1000], Loss: 1.8366411924362183\n",
            "Epoch [210/1000], Loss: 1.9037928581237793\n",
            "Epoch [211/1000], Loss: 1.8203599452972412\n",
            "Epoch [212/1000], Loss: 2.577183723449707\n",
            "Epoch [213/1000], Loss: 1.750704050064087\n",
            "Epoch [214/1000], Loss: 3.7293002605438232\n",
            "Epoch [215/1000], Loss: 1.7807831764221191\n",
            "Epoch [216/1000], Loss: 2.9180195331573486\n",
            "Epoch [217/1000], Loss: 1.8619645833969116\n",
            "Epoch [218/1000], Loss: 1.80050790309906\n",
            "Epoch [219/1000], Loss: 1.8718786239624023\n",
            "Epoch [220/1000], Loss: 2.410977363586426\n",
            "Epoch [221/1000], Loss: 1.8243526220321655\n",
            "Epoch [222/1000], Loss: 1.7484349012374878\n",
            "Epoch [223/1000], Loss: 2.7365798950195312\n",
            "Epoch [224/1000], Loss: 1.8026955127716064\n",
            "Epoch [225/1000], Loss: 1.8011324405670166\n",
            "Epoch [226/1000], Loss: 2.1069483757019043\n",
            "Epoch [227/1000], Loss: 1.7897721529006958\n",
            "Epoch [228/1000], Loss: 3.738327741622925\n",
            "Epoch [229/1000], Loss: 2.086948871612549\n",
            "Epoch [230/1000], Loss: 1.8781177997589111\n",
            "Epoch [231/1000], Loss: 1.811518669128418\n",
            "Epoch [232/1000], Loss: 2.440824508666992\n",
            "Epoch [233/1000], Loss: 1.7960025072097778\n",
            "Epoch [234/1000], Loss: 1.7657701969146729\n",
            "Epoch [235/1000], Loss: 1.8819794654846191\n",
            "Epoch [236/1000], Loss: 1.7434254884719849\n",
            "Epoch [237/1000], Loss: 2.1772618293762207\n",
            "Epoch [238/1000], Loss: 1.7512258291244507\n",
            "Epoch [239/1000], Loss: 1.8224583864212036\n",
            "Epoch [240/1000], Loss: 1.7550491094589233\n",
            "Epoch [241/1000], Loss: 1.8624927997589111\n",
            "Epoch [242/1000], Loss: 1.7594175338745117\n",
            "Epoch [243/1000], Loss: 1.7773773670196533\n",
            "Epoch [244/1000], Loss: 1.9198373556137085\n",
            "Epoch [245/1000], Loss: 3.6652474403381348\n",
            "Epoch [246/1000], Loss: 1.7667267322540283\n",
            "Epoch [247/1000], Loss: 2.1339478492736816\n",
            "Epoch [248/1000], Loss: 3.6936538219451904\n",
            "Epoch [249/1000], Loss: 1.7127777338027954\n",
            "Epoch [250/1000], Loss: 1.7966805696487427\n",
            "Epoch [251/1000], Loss: 2.1778571605682373\n",
            "Epoch [252/1000], Loss: 1.8081775903701782\n",
            "Epoch [253/1000], Loss: 1.763005256652832\n",
            "Epoch [254/1000], Loss: 2.0078721046447754\n",
            "Epoch [255/1000], Loss: 2.3092617988586426\n",
            "Epoch [256/1000], Loss: 1.7694114446640015\n",
            "Epoch [257/1000], Loss: 1.8561468124389648\n",
            "Epoch [258/1000], Loss: 1.7602410316467285\n",
            "Epoch [259/1000], Loss: 1.8418059349060059\n",
            "Epoch [260/1000], Loss: 1.9425922632217407\n",
            "Epoch [261/1000], Loss: 2.0648980140686035\n",
            "Epoch [262/1000], Loss: 1.792006015777588\n",
            "Epoch [263/1000], Loss: 2.122086763381958\n",
            "Epoch [264/1000], Loss: 1.7591021060943604\n",
            "Epoch [265/1000], Loss: 1.803346037864685\n",
            "Epoch [266/1000], Loss: 3.756643772125244\n",
            "Epoch [267/1000], Loss: 3.6751275062561035\n",
            "Epoch [268/1000], Loss: 1.761338472366333\n",
            "Epoch [269/1000], Loss: 3.789724826812744\n",
            "Epoch [270/1000], Loss: 1.9381657838821411\n",
            "Epoch [271/1000], Loss: 1.8698234558105469\n",
            "Epoch [272/1000], Loss: 1.7588684558868408\n",
            "Epoch [273/1000], Loss: 1.7426066398620605\n",
            "Epoch [274/1000], Loss: 1.7474987506866455\n",
            "Epoch [275/1000], Loss: 2.0782742500305176\n",
            "Epoch [276/1000], Loss: 2.024472713470459\n",
            "Epoch [277/1000], Loss: 1.8239672183990479\n",
            "Epoch [278/1000], Loss: 1.826902985572815\n",
            "Epoch [279/1000], Loss: 1.7642337083816528\n",
            "Epoch [280/1000], Loss: 3.802494525909424\n",
            "Epoch [281/1000], Loss: 1.8241767883300781\n",
            "Epoch [282/1000], Loss: 1.9002978801727295\n",
            "Epoch [283/1000], Loss: 1.921865463256836\n",
            "Epoch [284/1000], Loss: 1.824455738067627\n",
            "Epoch [285/1000], Loss: 1.873295783996582\n",
            "Epoch [286/1000], Loss: 1.8705612421035767\n",
            "Epoch [287/1000], Loss: 3.055065631866455\n",
            "Epoch [288/1000], Loss: 1.6808252334594727\n",
            "Epoch [289/1000], Loss: 1.7581188678741455\n",
            "Epoch [290/1000], Loss: 1.9456560611724854\n",
            "Epoch [291/1000], Loss: 1.804127812385559\n",
            "Epoch [292/1000], Loss: 1.8893181085586548\n",
            "Epoch [293/1000], Loss: 1.6773744821548462\n",
            "Epoch [294/1000], Loss: 1.7386164665222168\n",
            "Epoch [295/1000], Loss: 2.652143955230713\n",
            "Epoch [296/1000], Loss: 1.7734203338623047\n",
            "Epoch [297/1000], Loss: 1.7300199270248413\n",
            "Epoch [298/1000], Loss: 1.7452415227890015\n",
            "Epoch [299/1000], Loss: 1.9489085674285889\n",
            "Epoch [300/1000], Loss: 1.781211495399475\n",
            "Epoch [301/1000], Loss: 1.7281858921051025\n",
            "Epoch [302/1000], Loss: 2.223097324371338\n",
            "Epoch [303/1000], Loss: 1.760896921157837\n",
            "Epoch [304/1000], Loss: 1.8660666942596436\n",
            "Epoch [305/1000], Loss: 1.9951984882354736\n",
            "Epoch [306/1000], Loss: 1.7565457820892334\n",
            "Epoch [307/1000], Loss: 1.8088287115097046\n",
            "Epoch [308/1000], Loss: 1.7825953960418701\n",
            "Epoch [309/1000], Loss: 1.6995073556900024\n",
            "Epoch [310/1000], Loss: 1.82925546169281\n",
            "Epoch [311/1000], Loss: 1.81715989112854\n",
            "Epoch [312/1000], Loss: 3.7138736248016357\n",
            "Epoch [313/1000], Loss: 1.8615224361419678\n",
            "Epoch [314/1000], Loss: 1.8978089094161987\n",
            "Epoch [315/1000], Loss: 1.857157826423645\n",
            "Epoch [316/1000], Loss: 1.769608497619629\n",
            "Epoch [317/1000], Loss: 1.9796819686889648\n",
            "Epoch [318/1000], Loss: 1.9065756797790527\n",
            "Epoch [319/1000], Loss: 1.891204595565796\n",
            "Epoch [320/1000], Loss: 1.808045744895935\n",
            "Epoch [321/1000], Loss: 1.8109029531478882\n",
            "Epoch [322/1000], Loss: 1.9794840812683105\n",
            "Epoch [323/1000], Loss: 1.843398094177246\n",
            "Epoch [324/1000], Loss: 1.7455304861068726\n",
            "Epoch [325/1000], Loss: 1.6889967918395996\n",
            "Epoch [326/1000], Loss: 1.9482324123382568\n",
            "Epoch [327/1000], Loss: 1.7070664167404175\n",
            "Epoch [328/1000], Loss: 1.752252221107483\n",
            "Epoch [329/1000], Loss: 1.8342313766479492\n",
            "Epoch [330/1000], Loss: 1.8017767667770386\n",
            "Epoch [331/1000], Loss: 1.711065649986267\n",
            "Epoch [332/1000], Loss: 1.8870195150375366\n",
            "Epoch [333/1000], Loss: 1.8031269311904907\n",
            "Epoch [334/1000], Loss: 1.8324990272521973\n",
            "Epoch [335/1000], Loss: 1.7240487337112427\n",
            "Epoch [336/1000], Loss: 2.335972785949707\n",
            "Epoch [337/1000], Loss: 3.7209177017211914\n",
            "Epoch [338/1000], Loss: 1.799957513809204\n",
            "Epoch [339/1000], Loss: 1.8232743740081787\n",
            "Epoch [340/1000], Loss: 1.795080542564392\n",
            "Epoch [341/1000], Loss: 3.912095546722412\n",
            "Epoch [342/1000], Loss: 1.7448935508728027\n",
            "Epoch [343/1000], Loss: 1.8201278448104858\n",
            "Epoch [344/1000], Loss: 1.6570173501968384\n",
            "Epoch [345/1000], Loss: 1.9364516735076904\n",
            "Epoch [346/1000], Loss: 2.0843074321746826\n",
            "Epoch [347/1000], Loss: 1.9315294027328491\n",
            "Epoch [348/1000], Loss: 2.037113666534424\n",
            "Epoch [349/1000], Loss: 1.7692888975143433\n",
            "Epoch [350/1000], Loss: 1.9768781661987305\n",
            "Epoch [351/1000], Loss: 1.7593731880187988\n",
            "Epoch [352/1000], Loss: 1.8117995262145996\n",
            "Epoch [353/1000], Loss: 3.684156894683838\n",
            "Epoch [354/1000], Loss: 1.3996561765670776\n",
            "Epoch [355/1000], Loss: 1.9058796167373657\n",
            "Epoch [356/1000], Loss: 2.192436695098877\n",
            "Epoch [357/1000], Loss: 1.8487763404846191\n",
            "Epoch [358/1000], Loss: 1.743039846420288\n",
            "Epoch [359/1000], Loss: 2.7867655754089355\n",
            "Epoch [360/1000], Loss: 1.657540202140808\n",
            "Epoch [361/1000], Loss: 1.974351167678833\n",
            "Epoch [362/1000], Loss: 2.075324535369873\n",
            "Epoch [363/1000], Loss: 1.7754708528518677\n",
            "Epoch [364/1000], Loss: 1.7863361835479736\n",
            "Epoch [365/1000], Loss: 1.68491530418396\n",
            "Epoch [366/1000], Loss: 1.8948818445205688\n",
            "Epoch [367/1000], Loss: 1.7164924144744873\n",
            "Epoch [368/1000], Loss: 2.0165674686431885\n",
            "Epoch [369/1000], Loss: 1.804797649383545\n",
            "Epoch [370/1000], Loss: 1.6404742002487183\n",
            "Epoch [371/1000], Loss: 1.924009919166565\n",
            "Epoch [372/1000], Loss: 1.7040096521377563\n",
            "Epoch [373/1000], Loss: 1.7418519258499146\n",
            "Epoch [374/1000], Loss: 1.3502575159072876\n",
            "Epoch [375/1000], Loss: 1.7558695077896118\n",
            "Epoch [376/1000], Loss: 1.902806043624878\n",
            "Epoch [377/1000], Loss: 1.7065212726593018\n",
            "Epoch [378/1000], Loss: 1.7634146213531494\n",
            "Epoch [379/1000], Loss: 1.6384228467941284\n",
            "Epoch [380/1000], Loss: 1.8102151155471802\n",
            "Epoch [381/1000], Loss: 1.8479697704315186\n",
            "Epoch [382/1000], Loss: 1.5974571704864502\n",
            "Epoch [383/1000], Loss: 1.2905298471450806\n",
            "Epoch [384/1000], Loss: 1.3675222396850586\n",
            "Epoch [385/1000], Loss: 1.7549060583114624\n",
            "Epoch [386/1000], Loss: 1.8549202680587769\n",
            "Epoch [387/1000], Loss: 1.4551112651824951\n",
            "Epoch [388/1000], Loss: 1.1932114362716675\n",
            "Epoch [389/1000], Loss: 1.839933156967163\n",
            "Epoch [390/1000], Loss: 1.6732385158538818\n",
            "Epoch [391/1000], Loss: 1.6408593654632568\n",
            "Epoch [392/1000], Loss: 1.7284907102584839\n",
            "Epoch [393/1000], Loss: 3.8419785499572754\n",
            "Epoch [394/1000], Loss: 1.7796070575714111\n",
            "Epoch [395/1000], Loss: 3.8892605304718018\n",
            "Epoch [396/1000], Loss: 1.7013485431671143\n",
            "Epoch [397/1000], Loss: 1.9748507738113403\n",
            "Epoch [398/1000], Loss: 1.8586255311965942\n",
            "Epoch [399/1000], Loss: 1.7863446474075317\n",
            "Epoch [400/1000], Loss: 1.6774049997329712\n",
            "Epoch [401/1000], Loss: 1.8079503774642944\n",
            "Epoch [402/1000], Loss: 1.7339829206466675\n",
            "Epoch [403/1000], Loss: 1.7179561853408813\n",
            "Epoch [404/1000], Loss: 1.9114110469818115\n",
            "Epoch [405/1000], Loss: 1.7480392456054688\n",
            "Epoch [406/1000], Loss: 3.714700222015381\n",
            "Epoch [407/1000], Loss: 1.5609039068222046\n",
            "Epoch [408/1000], Loss: 1.232548713684082\n",
            "Epoch [409/1000], Loss: 1.7270134687423706\n",
            "Epoch [410/1000], Loss: 1.8313801288604736\n",
            "Epoch [411/1000], Loss: 1.6308172941207886\n",
            "Epoch [412/1000], Loss: 1.7751092910766602\n",
            "Epoch [413/1000], Loss: 1.6069252490997314\n",
            "Epoch [414/1000], Loss: 1.7228931188583374\n",
            "Epoch [415/1000], Loss: 1.1436355113983154\n",
            "Epoch [416/1000], Loss: 1.3491817712783813\n",
            "Epoch [417/1000], Loss: 1.7514103651046753\n",
            "Epoch [418/1000], Loss: 1.7664949893951416\n",
            "Epoch [419/1000], Loss: 1.9058129787445068\n",
            "Epoch [420/1000], Loss: 1.7527621984481812\n",
            "Epoch [421/1000], Loss: 1.535429835319519\n",
            "Epoch [422/1000], Loss: 1.6944350004196167\n",
            "Epoch [423/1000], Loss: 1.7287100553512573\n",
            "Epoch [424/1000], Loss: 1.6880444288253784\n",
            "Epoch [425/1000], Loss: 1.7454084157943726\n",
            "Epoch [426/1000], Loss: 1.6507468223571777\n",
            "Epoch [427/1000], Loss: 1.7419238090515137\n",
            "Epoch [428/1000], Loss: 1.029527187347412\n",
            "Epoch [429/1000], Loss: 1.5133060216903687\n",
            "Epoch [430/1000], Loss: 1.73504638671875\n",
            "Epoch [431/1000], Loss: 1.9361882209777832\n",
            "Epoch [432/1000], Loss: 1.703947901725769\n",
            "Epoch [433/1000], Loss: 1.788460373878479\n",
            "Epoch [434/1000], Loss: 1.6624891757965088\n",
            "Epoch [435/1000], Loss: 1.038869857788086\n",
            "Epoch [436/1000], Loss: 1.545139193534851\n",
            "Epoch [437/1000], Loss: 1.642287254333496\n",
            "Epoch [438/1000], Loss: 1.941942572593689\n",
            "Epoch [439/1000], Loss: 1.5929455757141113\n",
            "Epoch [440/1000], Loss: 1.7736914157867432\n",
            "Epoch [441/1000], Loss: 1.251598596572876\n",
            "Epoch [442/1000], Loss: 1.5460305213928223\n",
            "Epoch [443/1000], Loss: 1.97638738155365\n",
            "Epoch [444/1000], Loss: 1.5989506244659424\n",
            "Epoch [445/1000], Loss: 1.8270577192306519\n",
            "Epoch [446/1000], Loss: 1.6429181098937988\n",
            "Epoch [447/1000], Loss: 1.6702851057052612\n",
            "Epoch [448/1000], Loss: 1.745747447013855\n",
            "Epoch [449/1000], Loss: 1.7547372579574585\n",
            "Epoch [450/1000], Loss: 1.7900899648666382\n",
            "Epoch [451/1000], Loss: 1.8190124034881592\n",
            "Epoch [452/1000], Loss: 1.61680269241333\n",
            "Epoch [453/1000], Loss: 3.8035967350006104\n",
            "Epoch [454/1000], Loss: 1.7626718282699585\n",
            "Epoch [455/1000], Loss: 1.3435250520706177\n",
            "Epoch [456/1000], Loss: 3.9474246501922607\n",
            "Epoch [457/1000], Loss: 1.6994349956512451\n",
            "Epoch [458/1000], Loss: 1.748391032218933\n",
            "Epoch [459/1000], Loss: 1.735924243927002\n",
            "Epoch [460/1000], Loss: 1.9391705989837646\n",
            "Epoch [461/1000], Loss: 3.7500839233398438\n",
            "Epoch [462/1000], Loss: 1.752479910850525\n",
            "Epoch [463/1000], Loss: 1.5342400074005127\n",
            "Epoch [464/1000], Loss: 1.836633563041687\n",
            "Epoch [465/1000], Loss: 1.497847080230713\n",
            "Epoch [466/1000], Loss: 1.8551656007766724\n",
            "Epoch [467/1000], Loss: 1.8492711782455444\n",
            "Epoch [468/1000], Loss: 1.873054027557373\n",
            "Epoch [469/1000], Loss: 1.7033226490020752\n",
            "Epoch [470/1000], Loss: 1.7827136516571045\n",
            "Epoch [471/1000], Loss: 1.7491652965545654\n",
            "Epoch [472/1000], Loss: 1.6018856763839722\n",
            "Epoch [473/1000], Loss: 1.5419981479644775\n",
            "Epoch [474/1000], Loss: 3.695845603942871\n",
            "Epoch [475/1000], Loss: 1.937445878982544\n",
            "Epoch [476/1000], Loss: 1.7088900804519653\n",
            "Epoch [477/1000], Loss: 1.7847365140914917\n",
            "Epoch [478/1000], Loss: 1.7208729982376099\n",
            "Epoch [479/1000], Loss: 1.5670444965362549\n",
            "Epoch [480/1000], Loss: 1.7286086082458496\n",
            "Epoch [481/1000], Loss: 1.7860794067382812\n",
            "Epoch [482/1000], Loss: 1.690667748451233\n",
            "Epoch [483/1000], Loss: 1.6287208795547485\n",
            "Epoch [484/1000], Loss: 1.4865238666534424\n",
            "Epoch [485/1000], Loss: 1.6590943336486816\n",
            "Epoch [486/1000], Loss: 1.7859904766082764\n",
            "Epoch [487/1000], Loss: 1.679261565208435\n",
            "Epoch [488/1000], Loss: 1.2161422967910767\n",
            "Epoch [489/1000], Loss: 1.0090259313583374\n",
            "Epoch [490/1000], Loss: 1.888738751411438\n",
            "Epoch [491/1000], Loss: 1.6972148418426514\n",
            "Epoch [492/1000], Loss: 3.840304136276245\n",
            "Epoch [493/1000], Loss: 1.737095594406128\n",
            "Epoch [494/1000], Loss: 3.785120964050293\n",
            "Epoch [495/1000], Loss: 1.715449571609497\n",
            "Epoch [496/1000], Loss: 1.7139760255813599\n",
            "Epoch [497/1000], Loss: 1.0219781398773193\n",
            "Epoch [498/1000], Loss: 1.654287338256836\n",
            "Epoch [499/1000], Loss: 1.6129025220870972\n",
            "Epoch [500/1000], Loss: 3.7844295501708984\n",
            "Epoch [501/1000], Loss: 1.7396568059921265\n",
            "Epoch [502/1000], Loss: 1.7000641822814941\n",
            "Epoch [503/1000], Loss: 1.7254266738891602\n",
            "Epoch [504/1000], Loss: 1.671391248703003\n",
            "Epoch [505/1000], Loss: 1.0834801197052002\n",
            "Epoch [506/1000], Loss: 1.739443302154541\n",
            "Epoch [507/1000], Loss: 1.6979213953018188\n",
            "Epoch [508/1000], Loss: 0.7571870684623718\n",
            "Epoch [509/1000], Loss: 1.5483046770095825\n",
            "Epoch [510/1000], Loss: 3.7737808227539062\n",
            "Epoch [511/1000], Loss: 3.7670397758483887\n",
            "Epoch [512/1000], Loss: 1.802919864654541\n",
            "Epoch [513/1000], Loss: 1.7021210193634033\n",
            "Epoch [514/1000], Loss: 3.7454185485839844\n",
            "Epoch [515/1000], Loss: 1.669257402420044\n",
            "Epoch [516/1000], Loss: 1.739243984222412\n",
            "Epoch [517/1000], Loss: 1.722923994064331\n",
            "Epoch [518/1000], Loss: 0.8439629673957825\n",
            "Epoch [519/1000], Loss: 1.7274962663650513\n",
            "Epoch [520/1000], Loss: 3.69567608833313\n",
            "Epoch [521/1000], Loss: 1.4748945236206055\n",
            "Epoch [522/1000], Loss: 1.4654542207717896\n",
            "Epoch [523/1000], Loss: 1.461696982383728\n",
            "Epoch [524/1000], Loss: 3.7218210697174072\n",
            "Epoch [525/1000], Loss: 1.8540973663330078\n",
            "Epoch [526/1000], Loss: 1.6396180391311646\n",
            "Epoch [527/1000], Loss: 1.6590250730514526\n",
            "Epoch [528/1000], Loss: 1.8893646001815796\n",
            "Epoch [529/1000], Loss: 1.5972181558609009\n",
            "Epoch [530/1000], Loss: 1.7305279970169067\n",
            "Epoch [531/1000], Loss: 1.8192723989486694\n",
            "Epoch [532/1000], Loss: 3.676527500152588\n",
            "Epoch [533/1000], Loss: 3.679202079772949\n",
            "Epoch [534/1000], Loss: 3.718445301055908\n",
            "Epoch [535/1000], Loss: 1.680418848991394\n",
            "Epoch [536/1000], Loss: 1.6897385120391846\n",
            "Epoch [537/1000], Loss: 1.819946527481079\n",
            "Epoch [538/1000], Loss: 1.7000772953033447\n",
            "Epoch [539/1000], Loss: 1.7568330764770508\n",
            "Epoch [540/1000], Loss: 1.477292776107788\n",
            "Epoch [541/1000], Loss: 1.8566193580627441\n",
            "Epoch [542/1000], Loss: 0.9102193713188171\n",
            "Epoch [543/1000], Loss: 1.7678028345108032\n",
            "Epoch [544/1000], Loss: 1.0093879699707031\n",
            "Epoch [545/1000], Loss: 1.6410739421844482\n",
            "Epoch [546/1000], Loss: 1.6864948272705078\n",
            "Epoch [547/1000], Loss: 1.4518367052078247\n",
            "Epoch [548/1000], Loss: 1.6635433435440063\n",
            "Epoch [549/1000], Loss: 1.5229697227478027\n",
            "Epoch [550/1000], Loss: 1.8047232627868652\n",
            "Epoch [551/1000], Loss: 1.4843755960464478\n",
            "Epoch [552/1000], Loss: 1.717528223991394\n",
            "Epoch [553/1000], Loss: 1.784258484840393\n",
            "Epoch [554/1000], Loss: 1.170422077178955\n",
            "Epoch [555/1000], Loss: 1.6506495475769043\n",
            "Epoch [556/1000], Loss: 1.663001537322998\n",
            "Epoch [557/1000], Loss: 1.6782822608947754\n",
            "Epoch [558/1000], Loss: 0.8720880746841431\n",
            "Epoch [559/1000], Loss: 1.7252345085144043\n",
            "Epoch [560/1000], Loss: 1.9059851169586182\n",
            "Epoch [561/1000], Loss: 1.5376532077789307\n",
            "Epoch [562/1000], Loss: 1.4243048429489136\n",
            "Epoch [563/1000], Loss: 1.7058601379394531\n",
            "Epoch [564/1000], Loss: 1.6825525760650635\n",
            "Epoch [565/1000], Loss: 1.7137587070465088\n",
            "Epoch [566/1000], Loss: 1.6723757982254028\n",
            "Epoch [567/1000], Loss: 1.7614291906356812\n",
            "Epoch [568/1000], Loss: 1.7297658920288086\n",
            "Epoch [569/1000], Loss: 0.8537889122962952\n",
            "Epoch [570/1000], Loss: 1.685458779335022\n",
            "Epoch [571/1000], Loss: 0.7128832936286926\n",
            "Epoch [572/1000], Loss: 1.4270089864730835\n",
            "Epoch [573/1000], Loss: 1.5003515481948853\n",
            "Epoch [574/1000], Loss: 1.64963960647583\n",
            "Epoch [575/1000], Loss: 1.7428669929504395\n",
            "Epoch [576/1000], Loss: 1.665117859840393\n",
            "Epoch [577/1000], Loss: 0.7843582630157471\n",
            "Epoch [578/1000], Loss: 1.6352711915969849\n",
            "Epoch [579/1000], Loss: 1.7390118837356567\n",
            "Epoch [580/1000], Loss: 1.686178207397461\n",
            "Epoch [581/1000], Loss: 1.7899372577667236\n",
            "Epoch [582/1000], Loss: 1.7779754400253296\n",
            "Epoch [583/1000], Loss: 1.7567765712738037\n",
            "Epoch [584/1000], Loss: 1.8934754133224487\n",
            "Epoch [585/1000], Loss: 0.7253794074058533\n",
            "Epoch [586/1000], Loss: 1.7278653383255005\n",
            "Epoch [587/1000], Loss: 1.6902552843093872\n",
            "Epoch [588/1000], Loss: 1.4770303964614868\n",
            "Epoch [589/1000], Loss: 3.863414764404297\n",
            "Epoch [590/1000], Loss: 1.6217881441116333\n",
            "Epoch [591/1000], Loss: 1.3569012880325317\n",
            "Epoch [592/1000], Loss: 1.618510127067566\n",
            "Epoch [593/1000], Loss: 1.4848514795303345\n",
            "Epoch [594/1000], Loss: 1.6504733562469482\n",
            "Epoch [595/1000], Loss: 1.7452781200408936\n",
            "Epoch [596/1000], Loss: 1.7303822040557861\n",
            "Epoch [597/1000], Loss: 1.7541711330413818\n",
            "Epoch [598/1000], Loss: 1.7483614683151245\n",
            "Epoch [599/1000], Loss: 0.6986384987831116\n",
            "Epoch [600/1000], Loss: 1.5486732721328735\n",
            "Epoch [601/1000], Loss: 1.0690152645111084\n",
            "Epoch [602/1000], Loss: 3.7586002349853516\n",
            "Epoch [603/1000], Loss: 3.7548372745513916\n",
            "Epoch [604/1000], Loss: 1.6032172441482544\n",
            "Epoch [605/1000], Loss: 1.6575831174850464\n",
            "Epoch [606/1000], Loss: 4.054924011230469\n",
            "Epoch [607/1000], Loss: 1.757731318473816\n",
            "Epoch [608/1000], Loss: 1.6753052473068237\n",
            "Epoch [609/1000], Loss: 1.5288374423980713\n",
            "Epoch [610/1000], Loss: 1.6962565183639526\n",
            "Epoch [611/1000], Loss: 1.5627477169036865\n",
            "Epoch [612/1000], Loss: 1.4949969053268433\n",
            "Epoch [613/1000], Loss: 1.641374111175537\n",
            "Epoch [614/1000], Loss: 1.7340203523635864\n",
            "Epoch [615/1000], Loss: 1.7592920064926147\n",
            "Epoch [616/1000], Loss: 1.432782769203186\n",
            "Epoch [617/1000], Loss: 1.516213297843933\n",
            "Epoch [618/1000], Loss: 0.7540194988250732\n",
            "Epoch [619/1000], Loss: 0.9137579202651978\n",
            "Epoch [620/1000], Loss: 1.810683012008667\n",
            "Epoch [621/1000], Loss: 1.334160566329956\n",
            "Epoch [622/1000], Loss: 3.761148452758789\n",
            "Epoch [623/1000], Loss: 0.7824940085411072\n",
            "Epoch [624/1000], Loss: 3.73226261138916\n",
            "Epoch [625/1000], Loss: 3.7960362434387207\n",
            "Epoch [626/1000], Loss: 1.634894847869873\n",
            "Epoch [627/1000], Loss: 1.6254971027374268\n",
            "Epoch [628/1000], Loss: 1.2899433374404907\n",
            "Epoch [629/1000], Loss: 3.721801280975342\n",
            "Epoch [630/1000], Loss: 1.7123527526855469\n",
            "Epoch [631/1000], Loss: 0.7643899917602539\n",
            "Epoch [632/1000], Loss: 1.715670108795166\n",
            "Epoch [633/1000], Loss: 1.7092620134353638\n",
            "Epoch [634/1000], Loss: 1.6527807712554932\n",
            "Epoch [635/1000], Loss: 3.7516393661499023\n",
            "Epoch [636/1000], Loss: 1.389333963394165\n",
            "Epoch [637/1000], Loss: 1.7659564018249512\n",
            "Epoch [638/1000], Loss: 1.7144644260406494\n",
            "Epoch [639/1000], Loss: 1.6455413103103638\n",
            "Epoch [640/1000], Loss: 1.7063628435134888\n",
            "Epoch [641/1000], Loss: 1.5607136487960815\n",
            "Epoch [642/1000], Loss: 0.9834566116333008\n",
            "Epoch [643/1000], Loss: 1.7533169984817505\n",
            "Epoch [644/1000], Loss: 1.6536697149276733\n",
            "Epoch [645/1000], Loss: 1.5057356357574463\n",
            "Epoch [646/1000], Loss: 1.6790311336517334\n",
            "Epoch [647/1000], Loss: 1.399970293045044\n",
            "Epoch [648/1000], Loss: 1.6902395486831665\n",
            "Epoch [649/1000], Loss: 1.652268886566162\n",
            "Epoch [650/1000], Loss: 0.8979629874229431\n",
            "Epoch [651/1000], Loss: 1.7484731674194336\n",
            "Epoch [652/1000], Loss: 1.668472409248352\n",
            "Epoch [653/1000], Loss: 1.7090873718261719\n",
            "Epoch [654/1000], Loss: 1.5508548021316528\n",
            "Epoch [655/1000], Loss: 1.715842366218567\n",
            "Epoch [656/1000], Loss: 1.4562759399414062\n",
            "Epoch [657/1000], Loss: 0.6126488447189331\n",
            "Epoch [658/1000], Loss: 1.214437484741211\n",
            "Epoch [659/1000], Loss: 1.6524035930633545\n",
            "Epoch [660/1000], Loss: 1.7145154476165771\n",
            "Epoch [661/1000], Loss: 1.6508090496063232\n",
            "Epoch [662/1000], Loss: 1.2997819185256958\n",
            "Epoch [663/1000], Loss: 1.2269949913024902\n",
            "Epoch [664/1000], Loss: 1.3706659078598022\n",
            "Epoch [665/1000], Loss: 0.8514552116394043\n",
            "Epoch [666/1000], Loss: 3.718085289001465\n",
            "Epoch [667/1000], Loss: 0.6411530375480652\n",
            "Epoch [668/1000], Loss: 0.7521470189094543\n",
            "Epoch [669/1000], Loss: 1.667905569076538\n",
            "Epoch [670/1000], Loss: 1.6943306922912598\n",
            "Epoch [671/1000], Loss: 1.6511270999908447\n",
            "Epoch [672/1000], Loss: 1.3628398180007935\n",
            "Epoch [673/1000], Loss: 0.5844051241874695\n",
            "Epoch [674/1000], Loss: 3.869896173477173\n",
            "Epoch [675/1000], Loss: 1.719038486480713\n",
            "Epoch [676/1000], Loss: 0.6264550089836121\n",
            "Epoch [677/1000], Loss: 1.7370035648345947\n",
            "Epoch [678/1000], Loss: 1.691670298576355\n",
            "Epoch [679/1000], Loss: 3.80819034576416\n",
            "Epoch [680/1000], Loss: 1.7222412824630737\n",
            "Epoch [681/1000], Loss: 3.7739176750183105\n",
            "Epoch [682/1000], Loss: 1.3729921579360962\n",
            "Epoch [683/1000], Loss: 3.713955879211426\n",
            "Epoch [684/1000], Loss: 0.5552500486373901\n",
            "Epoch [685/1000], Loss: 1.6996593475341797\n",
            "Epoch [686/1000], Loss: 0.5114246606826782\n",
            "Epoch [687/1000], Loss: 1.6640127897262573\n",
            "Epoch [688/1000], Loss: 1.3987202644348145\n",
            "Epoch [689/1000], Loss: 0.7849286198616028\n",
            "Epoch [690/1000], Loss: 1.7523012161254883\n",
            "Epoch [691/1000], Loss: 3.949781894683838\n",
            "Epoch [692/1000], Loss: 1.438363790512085\n",
            "Epoch [693/1000], Loss: 1.646327257156372\n",
            "Epoch [694/1000], Loss: 1.0864249467849731\n",
            "Epoch [695/1000], Loss: 3.7169203758239746\n",
            "Epoch [696/1000], Loss: 3.6861019134521484\n",
            "Epoch [697/1000], Loss: 3.786473274230957\n",
            "Epoch [698/1000], Loss: 1.6910998821258545\n",
            "Epoch [699/1000], Loss: 1.4521342515945435\n",
            "Epoch [700/1000], Loss: 1.3455073833465576\n",
            "Epoch [701/1000], Loss: 1.5993592739105225\n",
            "Epoch [702/1000], Loss: 3.7177700996398926\n",
            "Epoch [703/1000], Loss: 1.6418591737747192\n",
            "Epoch [704/1000], Loss: 1.4000225067138672\n",
            "Epoch [705/1000], Loss: 0.6426425576210022\n",
            "Epoch [706/1000], Loss: 1.6049678325653076\n",
            "Epoch [707/1000], Loss: 1.6038403511047363\n",
            "Epoch [708/1000], Loss: 3.7403876781463623\n",
            "Epoch [709/1000], Loss: 3.659238338470459\n",
            "Epoch [710/1000], Loss: 1.7975138425827026\n",
            "Epoch [711/1000], Loss: 1.7089382410049438\n",
            "Epoch [712/1000], Loss: 1.6900432109832764\n",
            "Epoch [713/1000], Loss: 1.3651139736175537\n",
            "Epoch [714/1000], Loss: 1.4299604892730713\n",
            "Epoch [715/1000], Loss: 1.7403167486190796\n",
            "Epoch [716/1000], Loss: 1.6181260347366333\n",
            "Epoch [717/1000], Loss: 0.6484692692756653\n",
            "Epoch [718/1000], Loss: 0.7102440595626831\n",
            "Epoch [719/1000], Loss: 1.6591172218322754\n",
            "Epoch [720/1000], Loss: 1.2873337268829346\n",
            "Epoch [721/1000], Loss: 1.7596039772033691\n",
            "Epoch [722/1000], Loss: 3.659396171569824\n",
            "Epoch [723/1000], Loss: 1.6306836605072021\n",
            "Epoch [724/1000], Loss: 1.2250362634658813\n",
            "Epoch [725/1000], Loss: 1.1583377122879028\n",
            "Epoch [726/1000], Loss: 1.4462714195251465\n",
            "Epoch [727/1000], Loss: 1.6133065223693848\n",
            "Epoch [728/1000], Loss: 1.663818359375\n",
            "Epoch [729/1000], Loss: 3.784677028656006\n",
            "Epoch [730/1000], Loss: 1.3917137384414673\n",
            "Epoch [731/1000], Loss: 0.5566899180412292\n",
            "Epoch [732/1000], Loss: 1.6946628093719482\n",
            "Epoch [733/1000], Loss: 1.5390480756759644\n",
            "Epoch [734/1000], Loss: 1.3678032159805298\n",
            "Epoch [735/1000], Loss: 1.5572634935379028\n",
            "Epoch [736/1000], Loss: 1.6544772386550903\n",
            "Epoch [737/1000], Loss: 1.6606776714324951\n",
            "Epoch [738/1000], Loss: 1.7056397199630737\n",
            "Epoch [739/1000], Loss: 3.772517204284668\n",
            "Epoch [740/1000], Loss: 1.3909595012664795\n",
            "Epoch [741/1000], Loss: 1.6555235385894775\n",
            "Epoch [742/1000], Loss: 4.260462760925293\n",
            "Epoch [743/1000], Loss: 1.6174758672714233\n",
            "Epoch [744/1000], Loss: 0.796812891960144\n",
            "Epoch [745/1000], Loss: 1.6525108814239502\n",
            "Epoch [746/1000], Loss: 3.6884968280792236\n",
            "Epoch [747/1000], Loss: 1.0580966472625732\n",
            "Epoch [748/1000], Loss: 1.6814720630645752\n",
            "Epoch [749/1000], Loss: 1.678681492805481\n",
            "Epoch [750/1000], Loss: 0.5866948366165161\n",
            "Epoch [751/1000], Loss: 1.752423882484436\n",
            "Epoch [752/1000], Loss: 1.361864686012268\n",
            "Epoch [753/1000], Loss: 1.1944868564605713\n",
            "Epoch [754/1000], Loss: 1.6541897058486938\n",
            "Epoch [755/1000], Loss: 0.570396363735199\n",
            "Epoch [756/1000], Loss: 1.8532553911209106\n",
            "Epoch [757/1000], Loss: 0.9919158220291138\n",
            "Epoch [758/1000], Loss: 1.6105314493179321\n",
            "Epoch [759/1000], Loss: 1.6771889925003052\n",
            "Epoch [760/1000], Loss: 1.6183849573135376\n",
            "Epoch [761/1000], Loss: 1.5961413383483887\n",
            "Epoch [762/1000], Loss: 1.6894943714141846\n",
            "Epoch [763/1000], Loss: 1.3710812330245972\n",
            "Epoch [764/1000], Loss: 1.653570532798767\n",
            "Epoch [765/1000], Loss: 1.6531261205673218\n",
            "Epoch [766/1000], Loss: 1.6552222967147827\n",
            "Epoch [767/1000], Loss: 3.716658115386963\n",
            "Epoch [768/1000], Loss: 3.6531856060028076\n",
            "Epoch [769/1000], Loss: 1.6733181476593018\n",
            "Epoch [770/1000], Loss: 1.5154156684875488\n",
            "Epoch [771/1000], Loss: 1.6920751333236694\n",
            "Epoch [772/1000], Loss: 1.5570894479751587\n",
            "Epoch [773/1000], Loss: 0.46405553817749023\n",
            "Epoch [774/1000], Loss: 1.7976577281951904\n",
            "Epoch [775/1000], Loss: 1.2679296731948853\n",
            "Epoch [776/1000], Loss: 1.0649256706237793\n",
            "Epoch [777/1000], Loss: 1.6150521039962769\n",
            "Epoch [778/1000], Loss: 1.674945592880249\n",
            "Epoch [779/1000], Loss: 1.3562021255493164\n",
            "Epoch [780/1000], Loss: 1.103055715560913\n",
            "Epoch [781/1000], Loss: 1.6302579641342163\n",
            "Epoch [782/1000], Loss: 0.6547930240631104\n",
            "Epoch [783/1000], Loss: 1.6226710081100464\n",
            "Epoch [784/1000], Loss: 1.6958236694335938\n",
            "Epoch [785/1000], Loss: 1.6401629447937012\n",
            "Epoch [786/1000], Loss: 0.6131110787391663\n",
            "Epoch [787/1000], Loss: 1.23581862449646\n",
            "Epoch [788/1000], Loss: 0.4876726567745209\n",
            "Epoch [789/1000], Loss: 0.4949692189693451\n",
            "Epoch [790/1000], Loss: 1.390305519104004\n",
            "Epoch [791/1000], Loss: 1.630231261253357\n",
            "Epoch [792/1000], Loss: 1.6592148542404175\n",
            "Epoch [793/1000], Loss: 1.6279585361480713\n",
            "Epoch [794/1000], Loss: 1.677268147468567\n",
            "Epoch [795/1000], Loss: 3.6861777305603027\n",
            "Epoch [796/1000], Loss: 1.589482069015503\n",
            "Epoch [797/1000], Loss: 1.6573185920715332\n",
            "Epoch [798/1000], Loss: 1.5126703977584839\n",
            "Epoch [799/1000], Loss: 1.6424537897109985\n",
            "Epoch [800/1000], Loss: 1.6966522932052612\n",
            "Epoch [801/1000], Loss: 1.6789698600769043\n",
            "Epoch [802/1000], Loss: 1.7578142881393433\n",
            "Epoch [803/1000], Loss: 0.44187644124031067\n",
            "Epoch [804/1000], Loss: 1.4809573888778687\n",
            "Epoch [805/1000], Loss: 1.6636940240859985\n",
            "Epoch [806/1000], Loss: 1.6842927932739258\n",
            "Epoch [807/1000], Loss: 1.6305547952651978\n",
            "Epoch [808/1000], Loss: 1.7604914903640747\n",
            "Epoch [809/1000], Loss: 1.6931332349777222\n",
            "Epoch [810/1000], Loss: 1.6268408298492432\n",
            "Epoch [811/1000], Loss: 1.6328403949737549\n",
            "Epoch [812/1000], Loss: 1.6282429695129395\n",
            "Epoch [813/1000], Loss: 1.689800500869751\n",
            "Epoch [814/1000], Loss: 0.46898096799850464\n",
            "Epoch [815/1000], Loss: 0.7411432862281799\n",
            "Epoch [816/1000], Loss: 0.5281948447227478\n",
            "Epoch [817/1000], Loss: 1.6902230978012085\n",
            "Epoch [818/1000], Loss: 1.4059492349624634\n",
            "Epoch [819/1000], Loss: 1.5766438245773315\n",
            "Epoch [820/1000], Loss: 1.7219523191452026\n",
            "Epoch [821/1000], Loss: 1.566063642501831\n",
            "Epoch [822/1000], Loss: 1.6296288967132568\n",
            "Epoch [823/1000], Loss: 1.609360933303833\n",
            "Epoch [824/1000], Loss: 1.5706740617752075\n",
            "Epoch [825/1000], Loss: 3.7523229122161865\n",
            "Epoch [826/1000], Loss: 1.5444775819778442\n",
            "Epoch [827/1000], Loss: 1.7302799224853516\n",
            "Epoch [828/1000], Loss: 1.3695147037506104\n",
            "Epoch [829/1000], Loss: 1.3545392751693726\n",
            "Epoch [830/1000], Loss: 1.650395393371582\n",
            "Epoch [831/1000], Loss: 1.362960696220398\n",
            "Epoch [832/1000], Loss: 1.1748809814453125\n",
            "Epoch [833/1000], Loss: 1.7046823501586914\n",
            "Epoch [834/1000], Loss: 1.3310831785202026\n",
            "Epoch [835/1000], Loss: 0.5453215837478638\n",
            "Epoch [836/1000], Loss: 0.5456905364990234\n",
            "Epoch [837/1000], Loss: 1.338334083557129\n",
            "Epoch [838/1000], Loss: 3.772306442260742\n",
            "Epoch [839/1000], Loss: 1.1233854293823242\n",
            "Epoch [840/1000], Loss: 1.647463083267212\n",
            "Epoch [841/1000], Loss: 3.7359368801116943\n",
            "Epoch [842/1000], Loss: 1.0417516231536865\n",
            "Epoch [843/1000], Loss: 3.6621179580688477\n",
            "Epoch [844/1000], Loss: 1.4008625745773315\n",
            "Epoch [845/1000], Loss: 3.6755080223083496\n",
            "Epoch [846/1000], Loss: 1.3249404430389404\n",
            "Epoch [847/1000], Loss: 1.3954830169677734\n",
            "Epoch [848/1000], Loss: 0.5230170488357544\n",
            "Epoch [849/1000], Loss: 1.6306589841842651\n",
            "Epoch [850/1000], Loss: 3.8427681922912598\n",
            "Epoch [851/1000], Loss: 1.3804494142532349\n",
            "Epoch [852/1000], Loss: 1.520536184310913\n",
            "Epoch [853/1000], Loss: 0.4614350199699402\n",
            "Epoch [854/1000], Loss: 1.3960174322128296\n",
            "Epoch [855/1000], Loss: 1.381727933883667\n",
            "Epoch [856/1000], Loss: 0.546082079410553\n",
            "Epoch [857/1000], Loss: 1.6204913854599\n",
            "Epoch [858/1000], Loss: 1.6004350185394287\n",
            "Epoch [859/1000], Loss: 0.5877112150192261\n",
            "Epoch [860/1000], Loss: 3.6097323894500732\n",
            "Epoch [861/1000], Loss: 3.716977596282959\n",
            "Epoch [862/1000], Loss: 1.1035475730895996\n",
            "Epoch [863/1000], Loss: 1.6110334396362305\n",
            "Epoch [864/1000], Loss: 1.6221212148666382\n",
            "Epoch [865/1000], Loss: 1.6632719039916992\n",
            "Epoch [866/1000], Loss: 0.9305590987205505\n",
            "Epoch [867/1000], Loss: 0.9567001461982727\n",
            "Epoch [868/1000], Loss: 1.7007635831832886\n",
            "Epoch [869/1000], Loss: 1.691786527633667\n",
            "Epoch [870/1000], Loss: 0.9752779006958008\n",
            "Epoch [871/1000], Loss: 0.4978756606578827\n",
            "Epoch [872/1000], Loss: 3.629303455352783\n",
            "Epoch [873/1000], Loss: 1.4478224515914917\n",
            "Epoch [874/1000], Loss: 1.5110232830047607\n",
            "Epoch [875/1000], Loss: 1.5083879232406616\n",
            "Epoch [876/1000], Loss: 1.7820333242416382\n",
            "Epoch [877/1000], Loss: 1.6588459014892578\n",
            "Epoch [878/1000], Loss: 1.3688963651657104\n",
            "Epoch [879/1000], Loss: 0.4297287166118622\n",
            "Epoch [880/1000], Loss: 1.6057032346725464\n",
            "Epoch [881/1000], Loss: 0.6781187057495117\n",
            "Epoch [882/1000], Loss: 1.6360679864883423\n",
            "Epoch [883/1000], Loss: 1.6526784896850586\n",
            "Epoch [884/1000], Loss: 0.9450170993804932\n",
            "Epoch [885/1000], Loss: 0.9077878594398499\n",
            "Epoch [886/1000], Loss: 1.3326300382614136\n",
            "Epoch [887/1000], Loss: 1.6523973941802979\n",
            "Epoch [888/1000], Loss: 1.5136200189590454\n",
            "Epoch [889/1000], Loss: 1.6270323991775513\n",
            "Epoch [890/1000], Loss: 0.4623720347881317\n",
            "Epoch [891/1000], Loss: 1.688572883605957\n",
            "Epoch [892/1000], Loss: 1.3810346126556396\n",
            "Epoch [893/1000], Loss: 0.4162657558917999\n",
            "Epoch [894/1000], Loss: 1.346011757850647\n",
            "Epoch [895/1000], Loss: 0.8975219130516052\n",
            "Epoch [896/1000], Loss: 1.0723973512649536\n",
            "Epoch [897/1000], Loss: 1.6639564037322998\n",
            "Epoch [898/1000], Loss: 1.696733832359314\n",
            "Epoch [899/1000], Loss: 1.6008687019348145\n",
            "Epoch [900/1000], Loss: 1.615408182144165\n",
            "Epoch [901/1000], Loss: 1.6578848361968994\n",
            "Epoch [902/1000], Loss: 1.6224005222320557\n",
            "Epoch [903/1000], Loss: 3.6341772079467773\n",
            "Epoch [904/1000], Loss: 1.5489755868911743\n",
            "Epoch [905/1000], Loss: 0.4087231755256653\n",
            "Epoch [906/1000], Loss: 1.576419472694397\n",
            "Epoch [907/1000], Loss: 1.3598514795303345\n",
            "Epoch [908/1000], Loss: 0.41341355443000793\n",
            "Epoch [909/1000], Loss: 3.833097457885742\n",
            "Epoch [910/1000], Loss: 0.4097357392311096\n",
            "Epoch [911/1000], Loss: 1.6483826637268066\n",
            "Epoch [912/1000], Loss: 1.6492160558700562\n",
            "Epoch [913/1000], Loss: 3.696411371231079\n",
            "Epoch [914/1000], Loss: 1.4611202478408813\n",
            "Epoch [915/1000], Loss: 1.2903159856796265\n",
            "Epoch [916/1000], Loss: 1.5581623315811157\n",
            "Epoch [917/1000], Loss: 0.9277836084365845\n",
            "Epoch [918/1000], Loss: 0.9005147814750671\n",
            "Epoch [919/1000], Loss: 3.651885986328125\n",
            "Epoch [920/1000], Loss: 0.5734862685203552\n",
            "Epoch [921/1000], Loss: 1.6005160808563232\n",
            "Epoch [922/1000], Loss: 1.651719093322754\n",
            "Epoch [923/1000], Loss: 1.3418972492218018\n",
            "Epoch [924/1000], Loss: 0.4582161605358124\n",
            "Epoch [925/1000], Loss: 1.5501010417938232\n",
            "Epoch [926/1000], Loss: 0.5219617486000061\n",
            "Epoch [927/1000], Loss: 1.8281022310256958\n",
            "Epoch [928/1000], Loss: 1.6268582344055176\n",
            "Epoch [929/1000], Loss: 1.5723592042922974\n",
            "Epoch [930/1000], Loss: 1.6140786409378052\n",
            "Epoch [931/1000], Loss: 0.4598545432090759\n",
            "Epoch [932/1000], Loss: 1.628401756286621\n",
            "Epoch [933/1000], Loss: 1.3483095169067383\n",
            "Epoch [934/1000], Loss: 3.7682743072509766\n",
            "Epoch [935/1000], Loss: 1.6157212257385254\n",
            "Epoch [936/1000], Loss: 1.4805817604064941\n",
            "Epoch [937/1000], Loss: 1.569839596748352\n",
            "Epoch [938/1000], Loss: 0.529133141040802\n",
            "Epoch [939/1000], Loss: 0.8813963532447815\n",
            "Epoch [940/1000], Loss: 1.5811845064163208\n",
            "Epoch [941/1000], Loss: 1.6536768674850464\n",
            "Epoch [942/1000], Loss: 1.6595354080200195\n",
            "Epoch [943/1000], Loss: 1.653509497642517\n",
            "Epoch [944/1000], Loss: 1.6212472915649414\n",
            "Epoch [945/1000], Loss: 1.6495487689971924\n",
            "Epoch [946/1000], Loss: 0.4582814574241638\n",
            "Epoch [947/1000], Loss: 0.8827866911888123\n",
            "Epoch [948/1000], Loss: 0.9840106964111328\n",
            "Epoch [949/1000], Loss: 1.2956455945968628\n",
            "Epoch [950/1000], Loss: 1.5798444747924805\n",
            "Epoch [951/1000], Loss: 3.706751823425293\n",
            "Epoch [952/1000], Loss: 0.40067222714424133\n",
            "Epoch [953/1000], Loss: 1.2814544439315796\n",
            "Epoch [954/1000], Loss: 3.753887414932251\n",
            "Epoch [955/1000], Loss: 1.3056468963623047\n",
            "Epoch [956/1000], Loss: 1.6428123712539673\n",
            "Epoch [957/1000], Loss: 1.466381549835205\n",
            "Epoch [958/1000], Loss: 1.6259859800338745\n",
            "Epoch [959/1000], Loss: 1.6282342672348022\n",
            "Epoch [960/1000], Loss: 0.37122538685798645\n",
            "Epoch [961/1000], Loss: 1.664905309677124\n",
            "Epoch [962/1000], Loss: 0.4157315492630005\n",
            "Epoch [963/1000], Loss: 3.7313318252563477\n",
            "Epoch [964/1000], Loss: 1.5097466707229614\n",
            "Epoch [965/1000], Loss: 1.6519296169281006\n",
            "Epoch [966/1000], Loss: 0.91719651222229\n",
            "Epoch [967/1000], Loss: 1.5782259702682495\n",
            "Epoch [968/1000], Loss: 1.6251550912857056\n",
            "Epoch [969/1000], Loss: 1.614760160446167\n",
            "Epoch [970/1000], Loss: 1.6531929969787598\n",
            "Epoch [971/1000], Loss: 1.005115270614624\n",
            "Epoch [972/1000], Loss: 1.6251764297485352\n",
            "Epoch [973/1000], Loss: 1.61029851436615\n",
            "Epoch [974/1000], Loss: 0.3820194602012634\n",
            "Epoch [975/1000], Loss: 0.9735990762710571\n",
            "Epoch [976/1000], Loss: 3.676675319671631\n",
            "Epoch [977/1000], Loss: 0.9503533244132996\n",
            "Epoch [978/1000], Loss: 1.5436536073684692\n",
            "Epoch [979/1000], Loss: 1.5906902551651\n",
            "Epoch [980/1000], Loss: 1.623870611190796\n",
            "Epoch [981/1000], Loss: 1.5668869018554688\n",
            "Epoch [982/1000], Loss: 1.638033390045166\n",
            "Epoch [983/1000], Loss: 1.0121052265167236\n",
            "Epoch [984/1000], Loss: 0.9993422627449036\n",
            "Epoch [985/1000], Loss: 0.39065709710121155\n",
            "Epoch [986/1000], Loss: 1.6802998781204224\n",
            "Epoch [987/1000], Loss: 1.6410560607910156\n",
            "Epoch [988/1000], Loss: 1.2887986898422241\n",
            "Epoch [989/1000], Loss: 1.3262426853179932\n",
            "Epoch [990/1000], Loss: 1.533928394317627\n",
            "Epoch [991/1000], Loss: 1.3234093189239502\n",
            "Epoch [992/1000], Loss: 0.9617913961410522\n",
            "Epoch [993/1000], Loss: 1.5743783712387085\n",
            "Epoch [994/1000], Loss: 1.5466222763061523\n",
            "Epoch [995/1000], Loss: 1.3405048847198486\n",
            "Epoch [996/1000], Loss: 0.47467830777168274\n",
            "Epoch [997/1000], Loss: 1.2826350927352905\n",
            "Epoch [998/1000], Loss: 0.948388397693634\n",
            "Epoch [999/1000], Loss: 1.5974973440170288\n"
          ]
        }
      ],
      "source": [
        "num_labels = 8\n",
        "\n",
        "# Create Generator\n",
        "g = Generator()\n",
        "CE = torch.nn.CrossEntropyLoss()\n",
        "optimizer_G = torch.optim.Adam(g.parameters(), lr=opt.lr)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    # Tạo dữ liệu đầu vào ngẫu nhiên\n",
        "    y = torch.randint(0, 8, (1,))\n",
        "    y_encoded = F.one_hot(y, 8).float()\n",
        "    # Xóa gradient của Generator\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    # Tính toán output từ Generator\n",
        "    g_ = g(y_encoded).reshape(1,28)\n",
        "    # Tính toán dự đoán từ Discriminator\n",
        "    y_pred = model(g_)\n",
        "    # Tính loss và gradient\n",
        "    loss = CE(y_pred, y)\n",
        "    loss.backward()\n",
        "    # Cập nhật các tham số của Generator\n",
        "    optimizer_G.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    print(f\"Epoch [{epoch}/{opt.n_epochs}], Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nIlc5V5JfCu5",
        "outputId": "960cfd97-d6e0-4e24-9a50-23a01501ddb8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Vẽ biểu đồ loss\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8HJpbDafFFy"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
